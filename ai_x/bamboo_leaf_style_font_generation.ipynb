{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于CycleGAN的竹叶字体生成\n",
    "\n",
    "\n",
    "> 本案例运行需要较大内存，建议在Ascend/GPU上运行。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型介绍\n",
    "\n",
    "### 模型简介\n",
    "\n",
    "CycleGAN(Cycle Generative Adversarial Network) 即循环对抗生成网络，来自论文 [Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks](https://arxiv.org/abs/1703.10593) 。该模型实现了一种在没有配对示例的情况下学习将图像从源域 X 转换到目标域 Y 的方法。\n",
    "\n",
    "该模型一个重要应用领域是域迁移(Domain Adaptation)，可以通俗地理解为图像风格迁移。其实在 CycleGAN 之前，就已经有了域迁移模型，比如 Pix2Pix ，但是 Pix2Pix 要求训练数据必须是成对的，而现实生活中，要找到两个域（画风）中成对出现的图片是相当困难的，因此 CycleGAN 诞生了，它只需要两种域的数据，而不需要他们有严格对应关系，是一种新的无监督的图像迁移网络。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型结构\n",
    "\n",
    "CycleGAN 网络本质上是由两个镜像对称的 GAN 网络组成，其结构如下图所示（图片来源于原论文）：\n",
    "\n",
    "![CycleGAN](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.3.0rc2/tutorials/application/source_zh_cn/generative/images/CycleGAN.png)\n",
    "\n",
    "为了方便理解，这里以苹果和橘子为例介绍。上图中 $X$ 可以理解为苹果，$Y$ 为橘子；$G$ 为将苹果生成橘子风格的生成器，$F$ 为将橘子生成的苹果风格的生成器，$D_{X}$ 和 $D_{Y}$ 为其相应判别器，具体生成器和判别器的结构可见下文代码。模型最终能够输出两个模型的权重，分别将两种图像的风格进行彼此迁移，生成新的图像。\n",
    "\n",
    "该模型一个很重要的部分就是损失函数，在所有损失里面循环一致损失(Cycle Consistency Loss)是最重要的。循环损失的计算过程如下图所示（图片来源于原论文）：\n",
    "\n",
    "![Cycle Consistency Loss](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.3.0rc2/tutorials/application/source_zh_cn/generative/images/CycleGAN_1.png)\n",
    "\n",
    "图中苹果图片 $x$ 经过生成器 $G$ 得到伪橘子 $\\hat{Y}$，然后将伪橘子 $\\hat{Y}$ 结果送进生成器 $F$ 又产生苹果风格的结果 $\\hat{x}$，最后将生成的苹果风格结果 $\\hat{x}$ 与原苹果图片 $x$ 一起计算出循环一致损失，反之亦然。循环损失捕捉了这样的直觉，即如果我们从一个域转换到另一个域，然后再转换回来，我们应该到达我们开始的地方。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集\n",
    "\n",
    "本案例为CycleGAN在字体设计方面的衍生使用，使用的数据集分为两组，分别是内容图片，置于TrainA文件夹内；风格图片，置于TrainB文件夹内。通过训练可将TrainB文件夹内图片风格迁移至TrainA内容图片上。TrainA、TrainB文件夹内图片分辨率大小、格式应统一，推荐使用256px，72dpi或512px，72dpi大小的.jpg或.png格式图片。\n",
    "\n",
    "本案例中，TrainA放置楷体字体png带白底照片，可通过字库解包的python代码获得。TrainB文件夹内放置手动收集与处理的竹叶png带白底图片，通过机器学习的训练，将TrainB文件夹中竹叶的风格迁移至TrainA的楷体字体上，生成风格独特的竹叶字体。\n",
    "\n",
    "通过OTF或TTF字体库解包，获得需要进行转换的字体图片集。通过裁剪边缘、二值化、重置图片大小等图片处理方法，将字体图片中的文字尽量居中，且在上下左右留出适当的距离。本案例提供楷体文字png图片数据集300张，放置于TrainA文件夹内，数据集概览如下：\n",
    "\n",
    "![TrainA-dataset](https://mindspore-courses.obs.cn-north-4.myhuaweicloud.com/deep%20learning/AI%2BX/image/20240815-184509.PNG)\n",
    "\n",
    "通过手动搜集与处理的300张竹叶png图片数据，同样将其进行二值化与重置图片大小，放置于TrainB文件夹内。数据集概览如下：\n",
    "\n",
    "![TrainB-dataset](https://mindspore-courses.obs.cn-north-4.myhuaweicloud.com/deep%20learning/AI%2BX/image/20240815-184406.PNG)\n",
    "\n",
    "将TrainA与TrainB文件夹一同放置于根目录下的dataset文件夹内，完成数据集的预处理。\n",
    "\n",
    "### 数据集下载\n",
    "\n",
    "使用 `download` 接口下载数据集，并将下载后的数据集自动解压到当前目录下。数据下载之前需要使用 `pip install download` 安装 `download` 包。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  dataset.zip\n",
      "   creating: trainA/\n",
      "  inflating: trainA/A (1).png        \n",
      "  inflating: trainA/A (10).png       \n",
      "  inflating: trainA/A (100).png      \n",
      "  inflating: trainA/A (101).png      \n",
      "  inflating: trainA/A (102).png      \n",
      "  inflating: trainA/A (103).png      \n",
      "  inflating: trainA/A (104).png      \n",
      "  inflating: trainA/A (105).png      \n",
      "  inflating: trainA/A (106).png      \n",
      "  inflating: trainA/A (107).png      \n",
      "  inflating: trainA/A (108).png      \n",
      "  inflating: trainA/A (109).png      \n",
      "  inflating: trainA/A (11).png       \n",
      "  inflating: trainA/A (110).png      \n",
      "  inflating: trainA/A (111).png      \n",
      "  inflating: trainA/A (112).png      \n",
      "  inflating: trainA/A (113).png      \n",
      "  inflating: trainA/A (114).png      \n",
      "  inflating: trainA/A (115).png      \n",
      "  inflating: trainA/A (116).png      \n",
      "  inflating: trainA/A (117).png      \n",
      "  inflating: trainA/A (118).png      \n",
      "  inflating: trainA/A (119).png      \n",
      "  inflating: trainA/A (12).png       \n",
      "  inflating: trainA/A (120).png      \n",
      "  inflating: trainA/A (121).png      \n",
      "  inflating: trainA/A (122).png      \n",
      "  inflating: trainA/A (123).png      \n",
      "  inflating: trainA/A (124).png      \n",
      "  inflating: trainA/A (125).png      \n",
      "  inflating: trainA/A (126).png      \n",
      "  inflating: trainA/A (127).png      \n",
      "  inflating: trainA/A (128).png      \n",
      "  inflating: trainA/A (129).png      \n",
      "  inflating: trainA/A (13).png       \n",
      "  inflating: trainA/A (130).png      \n",
      "  inflating: trainA/A (131).png      \n",
      "  inflating: trainA/A (132).png      \n",
      "  inflating: trainA/A (133).png      \n",
      "  inflating: trainA/A (134).png      \n",
      "  inflating: trainA/A (135).png      \n",
      "  inflating: trainA/A (136).png      \n",
      "  inflating: trainA/A (137).png      \n",
      "  inflating: trainA/A (138).png      \n",
      "  inflating: trainA/A (139).png      \n",
      "  inflating: trainA/A (14).png       \n",
      "  inflating: trainA/A (140).png      \n",
      "  inflating: trainA/A (141).png      \n",
      "  inflating: trainA/A (142).png      \n",
      "  inflating: trainA/A (143).png      \n",
      "  inflating: trainA/A (144).png      \n",
      "  inflating: trainA/A (145).png      \n",
      "  inflating: trainA/A (146).png      \n",
      "  inflating: trainA/A (147).png      \n",
      "  inflating: trainA/A (148).png      \n",
      "  inflating: trainA/A (149).png      \n",
      "  inflating: trainA/A (15).png       \n",
      "  inflating: trainA/A (150).png      \n",
      "  inflating: trainA/A (151).png      \n",
      "  inflating: trainA/A (152).png      \n",
      "  inflating: trainA/A (153).png      \n",
      "  inflating: trainA/A (154).png      \n",
      "  inflating: trainA/A (155).png      \n",
      "  inflating: trainA/A (156).png      \n",
      "  inflating: trainA/A (157).png      \n",
      "  inflating: trainA/A (158).png      \n",
      "  inflating: trainA/A (159).png      \n",
      "  inflating: trainA/A (16).png       \n",
      "  inflating: trainA/A (160).png      \n",
      "  inflating: trainA/A (161).png      \n",
      "  inflating: trainA/A (162).png      \n",
      "  inflating: trainA/A (163).png      \n",
      "  inflating: trainA/A (164).png      \n",
      "  inflating: trainA/A (165).png      \n",
      "  inflating: trainA/A (166).png      \n",
      "  inflating: trainA/A (167).png      \n",
      "  inflating: trainA/A (168).png      \n",
      "  inflating: trainA/A (169).png      \n",
      "  inflating: trainA/A (17).png       \n",
      "  inflating: trainA/A (170).png      \n",
      "  inflating: trainA/A (171).png      \n",
      "  inflating: trainA/A (172).png      \n",
      "  inflating: trainA/A (173).png      \n",
      "  inflating: trainA/A (174).png      \n",
      "  inflating: trainA/A (175).png      \n",
      "  inflating: trainA/A (176).png      \n",
      "  inflating: trainA/A (177).png      \n",
      "  inflating: trainA/A (178).png      \n",
      "  inflating: trainA/A (179).png      \n",
      "  inflating: trainA/A (18).png       \n",
      "  inflating: trainA/A (180).png      \n",
      "  inflating: trainA/A (181).png      \n",
      "  inflating: trainA/A (182).png      \n",
      "  inflating: trainA/A (183).png      \n",
      "  inflating: trainA/A (184).png      \n",
      "  inflating: trainA/A (185).png      \n",
      "  inflating: trainA/A (186).png      \n",
      "  inflating: trainA/A (187).png      \n",
      "  inflating: trainA/A (188).png      \n",
      "  inflating: trainA/A (189).png      \n",
      "  inflating: trainA/A (19).png       \n",
      "  inflating: trainA/A (190).png      \n",
      "  inflating: trainA/A (191).png      \n",
      "  inflating: trainA/A (192).png      \n",
      "  inflating: trainA/A (193).png      \n",
      "  inflating: trainA/A (194).png      \n",
      "  inflating: trainA/A (195).png      \n",
      "  inflating: trainA/A (196).png      \n",
      "  inflating: trainA/A (197).png      \n",
      "  inflating: trainA/A (198).png      \n",
      "  inflating: trainA/A (199).png      \n",
      "  inflating: trainA/A (2).png        \n",
      "  inflating: trainA/A (20).png       \n",
      "  inflating: trainA/A (200).png      \n",
      "  inflating: trainA/A (201).png      \n",
      "  inflating: trainA/A (202).png      \n",
      "  inflating: trainA/A (203).png      \n",
      "  inflating: trainA/A (204).png      \n",
      "  inflating: trainA/A (205).png      \n",
      "  inflating: trainA/A (206).png      \n",
      "  inflating: trainA/A (207).png      \n",
      "  inflating: trainA/A (208).png      \n",
      "  inflating: trainA/A (209).png      \n",
      "  inflating: trainA/A (21).png       \n",
      "  inflating: trainA/A (210).png      \n",
      "  inflating: trainA/A (211).png      \n",
      "  inflating: trainA/A (212).png      \n",
      "  inflating: trainA/A (213).png      \n",
      "  inflating: trainA/A (214).png      \n",
      "  inflating: trainA/A (215).png      \n",
      "  inflating: trainA/A (216).png      \n",
      "  inflating: trainA/A (217).png      \n",
      "  inflating: trainA/A (218).png      \n",
      "  inflating: trainA/A (219).png      \n",
      "  inflating: trainA/A (22).png       \n",
      "  inflating: trainA/A (220).png      \n",
      "  inflating: trainA/A (221).png      \n",
      "  inflating: trainA/A (222).png      \n",
      "  inflating: trainA/A (223).png      \n",
      "  inflating: trainA/A (224).png      \n",
      "  inflating: trainA/A (225).png      \n",
      "  inflating: trainA/A (226).png      \n",
      "  inflating: trainA/A (227).png      \n",
      "  inflating: trainA/A (228).png      \n",
      "  inflating: trainA/A (229).png      \n",
      "  inflating: trainA/A (23).png       \n",
      "  inflating: trainA/A (230).png      \n",
      "  inflating: trainA/A (231).png      \n",
      "  inflating: trainA/A (232).png      \n",
      "  inflating: trainA/A (233).png      \n",
      "  inflating: trainA/A (234).png      \n",
      "  inflating: trainA/A (235).png      \n",
      "  inflating: trainA/A (236).png      \n",
      "  inflating: trainA/A (237).png      \n",
      "  inflating: trainA/A (238).png      \n",
      "  inflating: trainA/A (239).png      \n",
      "  inflating: trainA/A (24).png       \n",
      "  inflating: trainA/A (240).png      \n",
      "  inflating: trainA/A (241).png      \n",
      "  inflating: trainA/A (242).png      \n",
      "  inflating: trainA/A (243).png      \n",
      "  inflating: trainA/A (244).png      \n",
      "  inflating: trainA/A (245).png      \n",
      "  inflating: trainA/A (246).png      \n",
      "  inflating: trainA/A (247).png      \n",
      "  inflating: trainA/A (248).png      \n",
      "  inflating: trainA/A (249).png      \n",
      "  inflating: trainA/A (25).png       \n",
      "  inflating: trainA/A (250).png      \n",
      "  inflating: trainA/A (251).png      \n",
      "  inflating: trainA/A (252).png      \n",
      "  inflating: trainA/A (253).png      \n",
      "  inflating: trainA/A (254).png      \n",
      "  inflating: trainA/A (255).png      \n",
      "  inflating: trainA/A (256).png      \n",
      "  inflating: trainA/A (257).png      \n",
      "  inflating: trainA/A (258).png      \n",
      "  inflating: trainA/A (259).png      \n",
      "  inflating: trainA/A (26).png       \n",
      "  inflating: trainA/A (260).png      \n",
      "  inflating: trainA/A (261).png      \n",
      "  inflating: trainA/A (262).png      \n",
      "  inflating: trainA/A (263).png      \n",
      "  inflating: trainA/A (264).png      \n",
      "  inflating: trainA/A (265).png      \n",
      "  inflating: trainA/A (266).png      \n",
      "  inflating: trainA/A (267).png      \n",
      "  inflating: trainA/A (268).png      \n",
      "  inflating: trainA/A (269).png      \n",
      "  inflating: trainA/A (27).png       \n",
      "  inflating: trainA/A (270).png      \n",
      "  inflating: trainA/A (271).png      \n",
      "  inflating: trainA/A (272).png      \n",
      "  inflating: trainA/A (273).png      \n",
      "  inflating: trainA/A (274).png      \n",
      "  inflating: trainA/A (275).png      \n",
      "  inflating: trainA/A (276).png      \n",
      "  inflating: trainA/A (277).png      \n",
      "  inflating: trainA/A (278).png      \n",
      "  inflating: trainA/A (279).png      \n",
      "  inflating: trainA/A (28).png       \n",
      "  inflating: trainA/A (280).png      \n",
      "  inflating: trainA/A (281).png      \n",
      "  inflating: trainA/A (282).png      \n",
      "  inflating: trainA/A (283).png      \n",
      "  inflating: trainA/A (284).png      \n",
      "  inflating: trainA/A (285).png      \n",
      "  inflating: trainA/A (286).png      \n",
      "  inflating: trainA/A (287).png      \n",
      "  inflating: trainA/A (288).png      \n",
      "  inflating: trainA/A (289).png      \n",
      "  inflating: trainA/A (29).png       \n",
      "  inflating: trainA/A (290).png      \n",
      "  inflating: trainA/A (291).png      \n",
      "  inflating: trainA/A (292).png      \n",
      "  inflating: trainA/A (293).png      \n",
      "  inflating: trainA/A (294).png      \n",
      "  inflating: trainA/A (295).png      \n",
      "  inflating: trainA/A (296).png      \n",
      "  inflating: trainA/A (297).png      \n",
      "  inflating: trainA/A (298).png      \n",
      "  inflating: trainA/A (299).png      \n",
      "  inflating: trainA/A (3).png        \n",
      "  inflating: trainA/A (30).png       \n",
      "  inflating: trainA/A (300).png      \n",
      "  inflating: trainA/A (31).png       \n",
      "  inflating: trainA/A (32).png       \n",
      "  inflating: trainA/A (33).png       \n",
      "  inflating: trainA/A (34).png       \n",
      "  inflating: trainA/A (35).png       \n",
      "  inflating: trainA/A (36).png       \n",
      "  inflating: trainA/A (37).png       \n",
      "  inflating: trainA/A (38).png       \n",
      "  inflating: trainA/A (39).png       \n",
      "  inflating: trainA/A (4).png        \n",
      "  inflating: trainA/A (40).png       \n",
      "  inflating: trainA/A (41).png       \n",
      "  inflating: trainA/A (42).png       \n",
      "  inflating: trainA/A (43).png       \n",
      "  inflating: trainA/A (44).png       \n",
      "  inflating: trainA/A (45).png       \n",
      "  inflating: trainA/A (46).png       \n",
      "  inflating: trainA/A (47).png       \n",
      "  inflating: trainA/A (48).png       \n",
      "  inflating: trainA/A (49).png       \n",
      "  inflating: trainA/A (5).png        \n",
      "  inflating: trainA/A (50).png       \n",
      "  inflating: trainA/A (51).png       \n",
      "  inflating: trainA/A (52).png       \n",
      "  inflating: trainA/A (53).png       \n",
      "  inflating: trainA/A (54).png       \n",
      "  inflating: trainA/A (55).png       \n",
      "  inflating: trainA/A (56).png       \n",
      "  inflating: trainA/A (57).png       \n",
      "  inflating: trainA/A (58).png       \n",
      "  inflating: trainA/A (59).png       \n",
      "  inflating: trainA/A (6).png        \n",
      "  inflating: trainA/A (60).png       \n",
      "  inflating: trainA/A (61).png       \n",
      "  inflating: trainA/A (62).png       \n",
      "  inflating: trainA/A (63).png       \n",
      "  inflating: trainA/A (64).png       \n",
      "  inflating: trainA/A (65).png       \n",
      "  inflating: trainA/A (66).png       \n",
      "  inflating: trainA/A (67).png       \n",
      "  inflating: trainA/A (68).png       \n",
      "  inflating: trainA/A (69).png       \n",
      "  inflating: trainA/A (7).png        \n",
      "  inflating: trainA/A (70).png       \n",
      "  inflating: trainA/A (71).png       \n",
      "  inflating: trainA/A (72).png       \n",
      "  inflating: trainA/A (73).png       \n",
      "  inflating: trainA/A (74).png       \n",
      "  inflating: trainA/A (75).png       \n",
      "  inflating: trainA/A (76).png       \n",
      "  inflating: trainA/A (77).png       \n",
      "  inflating: trainA/A (78).png       \n",
      "  inflating: trainA/A (79).png       \n",
      "  inflating: trainA/A (8).png        \n",
      "  inflating: trainA/A (80).png       \n",
      "  inflating: trainA/A (81).png       \n",
      "  inflating: trainA/A (82).png       \n",
      "  inflating: trainA/A (83).png       \n",
      "  inflating: trainA/A (84).png       \n",
      "  inflating: trainA/A (85).png       \n",
      "  inflating: trainA/A (86).png       \n",
      "  inflating: trainA/A (87).png       \n",
      "  inflating: trainA/A (88).png       \n",
      "  inflating: trainA/A (89).png       \n",
      "  inflating: trainA/A (9).png        \n",
      "  inflating: trainA/A (90).png       \n",
      "  inflating: trainA/A (91).png       \n",
      "  inflating: trainA/A (92).png       \n",
      "  inflating: trainA/A (93).png       \n",
      "  inflating: trainA/A (94).png       \n",
      "  inflating: trainA/A (95).png       \n",
      "  inflating: trainA/A (96).png       \n",
      "  inflating: trainA/A (97).png       \n",
      "  inflating: trainA/A (98).png       \n",
      "  inflating: trainA/A (99).png       \n",
      "   creating: trainB/\n",
      "  inflating: trainB/B (1).png        \n",
      "  inflating: trainB/B (10).png       \n",
      "  inflating: trainB/B (100).png      \n",
      "  inflating: trainB/B (101).png      \n",
      "  inflating: trainB/B (102).png      \n",
      "  inflating: trainB/B (103).png      \n",
      "  inflating: trainB/B (104).png      \n",
      "  inflating: trainB/B (105).png      \n",
      "  inflating: trainB/B (106).png      \n",
      "  inflating: trainB/B (107).png      \n",
      "  inflating: trainB/B (108).png      \n",
      "  inflating: trainB/B (109).png      \n",
      "  inflating: trainB/B (11).png       \n",
      "  inflating: trainB/B (110).png      \n",
      "  inflating: trainB/B (111).png      \n",
      "  inflating: trainB/B (112).png      \n",
      "  inflating: trainB/B (113).png      \n",
      "  inflating: trainB/B (114).png      \n",
      "  inflating: trainB/B (115).png      \n",
      "  inflating: trainB/B (116).png      \n",
      "  inflating: trainB/B (117).png      \n",
      "  inflating: trainB/B (118).png      \n",
      "  inflating: trainB/B (119).png      \n",
      "  inflating: trainB/B (12).png       \n",
      "  inflating: trainB/B (120).png      \n",
      "  inflating: trainB/B (121).png      \n",
      "  inflating: trainB/B (122).png      \n",
      "  inflating: trainB/B (123).png      \n",
      "  inflating: trainB/B (124).png      \n",
      "  inflating: trainB/B (125).png      \n",
      "  inflating: trainB/B (126).png      \n",
      "  inflating: trainB/B (127).png      \n",
      "  inflating: trainB/B (128).png      \n",
      "  inflating: trainB/B (129).png      \n",
      "  inflating: trainB/B (13).png       \n",
      "  inflating: trainB/B (130).png      \n",
      "  inflating: trainB/B (131).png      \n",
      "  inflating: trainB/B (132).png      \n",
      "  inflating: trainB/B (133).png      \n",
      "  inflating: trainB/B (134).png      \n",
      "  inflating: trainB/B (135).png      \n",
      "  inflating: trainB/B (136).png      \n",
      "  inflating: trainB/B (137).png      \n",
      "  inflating: trainB/B (138).png      \n",
      "  inflating: trainB/B (139).png      \n",
      "  inflating: trainB/B (14).png       \n",
      "  inflating: trainB/B (140).png      \n",
      "  inflating: trainB/B (141).png      \n",
      "  inflating: trainB/B (142).png      \n",
      "  inflating: trainB/B (143).png      \n",
      "  inflating: trainB/B (144).png      \n",
      "  inflating: trainB/B (145).png      \n",
      "  inflating: trainB/B (146).png      \n",
      "  inflating: trainB/B (147).png      \n",
      "  inflating: trainB/B (148).png      \n",
      "  inflating: trainB/B (149).png      \n",
      "  inflating: trainB/B (15).png       \n",
      "  inflating: trainB/B (150).png      \n",
      "  inflating: trainB/B (151).png      \n",
      "  inflating: trainB/B (152).png      \n",
      "  inflating: trainB/B (153).png      \n",
      "  inflating: trainB/B (154).png      \n",
      "  inflating: trainB/B (155).png      \n",
      "  inflating: trainB/B (156).png      \n",
      "  inflating: trainB/B (157).png      \n",
      "  inflating: trainB/B (158).png      \n",
      "  inflating: trainB/B (159).png      \n",
      "  inflating: trainB/B (16).png       \n",
      "  inflating: trainB/B (160).png      \n",
      "  inflating: trainB/B (161).png      \n",
      "  inflating: trainB/B (162).png      \n",
      "  inflating: trainB/B (163).png      \n",
      "  inflating: trainB/B (164).png      \n",
      "  inflating: trainB/B (165).png      \n",
      "  inflating: trainB/B (166).png      \n",
      "  inflating: trainB/B (167).png      \n",
      "  inflating: trainB/B (168).png      \n",
      "  inflating: trainB/B (169).png      \n",
      "  inflating: trainB/B (17).png       \n",
      "  inflating: trainB/B (170).png      \n",
      "  inflating: trainB/B (171).png      \n",
      "  inflating: trainB/B (172).png      \n",
      "  inflating: trainB/B (173).png      \n",
      "  inflating: trainB/B (174).png      \n",
      "  inflating: trainB/B (175).png      \n",
      "  inflating: trainB/B (176).png      \n",
      "  inflating: trainB/B (177).png      \n",
      "  inflating: trainB/B (178).png      \n",
      "  inflating: trainB/B (179).png      \n",
      "  inflating: trainB/B (18).png       \n",
      "  inflating: trainB/B (180).png      \n",
      "  inflating: trainB/B (181).png      \n",
      "  inflating: trainB/B (182).png      \n",
      "  inflating: trainB/B (183).png      \n",
      "  inflating: trainB/B (184).png      \n",
      "  inflating: trainB/B (185).png      \n",
      "  inflating: trainB/B (186).png      \n",
      "  inflating: trainB/B (187).png      \n",
      "  inflating: trainB/B (188).png      \n",
      "  inflating: trainB/B (189).png      \n",
      "  inflating: trainB/B (19).png       \n",
      "  inflating: trainB/B (190).png      \n",
      "  inflating: trainB/B (191).png      \n",
      "  inflating: trainB/B (192).png      \n",
      "  inflating: trainB/B (193).png      \n",
      "  inflating: trainB/B (194).png      \n",
      "  inflating: trainB/B (195).png      \n",
      "  inflating: trainB/B (196).png      \n",
      "  inflating: trainB/B (197).png      \n",
      "  inflating: trainB/B (198).png      \n",
      "  inflating: trainB/B (199).png      \n",
      "  inflating: trainB/B (2).png        \n",
      "  inflating: trainB/B (20).png       \n",
      "  inflating: trainB/B (200).png      \n",
      "  inflating: trainB/B (201).png      \n",
      "  inflating: trainB/B (202).png      \n",
      "  inflating: trainB/B (203).png      \n",
      "  inflating: trainB/B (204).png      \n",
      "  inflating: trainB/B (205).png      \n",
      "  inflating: trainB/B (206).png      \n",
      "  inflating: trainB/B (207).png      \n",
      "  inflating: trainB/B (208).png      \n",
      "  inflating: trainB/B (209).png      \n",
      "  inflating: trainB/B (21).png       \n",
      "  inflating: trainB/B (210).png      \n",
      "  inflating: trainB/B (211).png      \n",
      "  inflating: trainB/B (212).png      \n",
      "  inflating: trainB/B (213).png      \n",
      "  inflating: trainB/B (214).png      \n",
      "  inflating: trainB/B (215).png      \n",
      "  inflating: trainB/B (216).png      \n",
      "  inflating: trainB/B (217).png      \n",
      "  inflating: trainB/B (218).png      \n",
      "  inflating: trainB/B (219).png      \n",
      "  inflating: trainB/B (22).png       \n",
      "  inflating: trainB/B (220).png      \n",
      "  inflating: trainB/B (221).png      \n",
      "  inflating: trainB/B (222).png      \n",
      "  inflating: trainB/B (223).png      \n",
      "  inflating: trainB/B (224).png      \n",
      "  inflating: trainB/B (225).png      \n",
      "  inflating: trainB/B (226).png      \n",
      "  inflating: trainB/B (227).png      \n",
      "  inflating: trainB/B (228).png      \n",
      "  inflating: trainB/B (229).png      \n",
      "  inflating: trainB/B (23).png       \n",
      "  inflating: trainB/B (230).png      \n",
      "  inflating: trainB/B (231).png      \n",
      "  inflating: trainB/B (232).png      \n",
      "  inflating: trainB/B (233).png      \n",
      "  inflating: trainB/B (234).png      \n",
      "  inflating: trainB/B (235).png      \n",
      "  inflating: trainB/B (236).png      \n",
      "  inflating: trainB/B (237).png      \n",
      "  inflating: trainB/B (238).png      \n",
      "  inflating: trainB/B (239).png      \n",
      "  inflating: trainB/B (24).png       \n",
      "  inflating: trainB/B (240).png      \n",
      "  inflating: trainB/B (241).png      \n",
      "  inflating: trainB/B (242).png      \n",
      "  inflating: trainB/B (243).png      \n",
      "  inflating: trainB/B (244).png      \n",
      "  inflating: trainB/B (245).png      \n",
      "  inflating: trainB/B (246).png      \n",
      "  inflating: trainB/B (247).png      \n",
      "  inflating: trainB/B (248).png      \n",
      "  inflating: trainB/B (249).png      \n",
      "  inflating: trainB/B (25).png       \n",
      "  inflating: trainB/B (250).png      \n",
      "  inflating: trainB/B (251).png      \n",
      "  inflating: trainB/B (252).png      \n",
      "  inflating: trainB/B (253).png      \n",
      "  inflating: trainB/B (254).png      \n",
      "  inflating: trainB/B (255).png      \n",
      "  inflating: trainB/B (256).png      \n",
      "  inflating: trainB/B (257).png      \n",
      "  inflating: trainB/B (258).png      \n",
      "  inflating: trainB/B (259).png      \n",
      "  inflating: trainB/B (26).png       \n",
      "  inflating: trainB/B (260).png      \n",
      "  inflating: trainB/B (261).png      \n",
      "  inflating: trainB/B (262).png      \n",
      "  inflating: trainB/B (263).png      \n",
      "  inflating: trainB/B (264).png      \n",
      "  inflating: trainB/B (265).png      \n",
      "  inflating: trainB/B (266).png      \n",
      "  inflating: trainB/B (267).png      \n",
      "  inflating: trainB/B (268).png      \n",
      "  inflating: trainB/B (269).png      \n",
      "  inflating: trainB/B (27).png       \n",
      "  inflating: trainB/B (270).png      \n",
      "  inflating: trainB/B (271).png      \n",
      "  inflating: trainB/B (272).png      \n",
      "  inflating: trainB/B (273).png      \n",
      "  inflating: trainB/B (274).png      \n",
      "  inflating: trainB/B (275).png      \n",
      "  inflating: trainB/B (276).png      \n",
      "  inflating: trainB/B (277).png      \n",
      "  inflating: trainB/B (278).png      \n",
      "  inflating: trainB/B (279).png      \n",
      "  inflating: trainB/B (28).png       \n",
      "  inflating: trainB/B (280).png      \n",
      "  inflating: trainB/B (281).png      \n",
      "  inflating: trainB/B (282).png      \n",
      "  inflating: trainB/B (283).png      \n",
      "  inflating: trainB/B (284).png      \n",
      "  inflating: trainB/B (285).png      \n",
      "  inflating: trainB/B (286).png      \n",
      "  inflating: trainB/B (287).png      \n",
      "  inflating: trainB/B (288).png      \n",
      "  inflating: trainB/B (289).png      \n",
      "  inflating: trainB/B (29).png       \n",
      "  inflating: trainB/B (290).png      \n",
      "  inflating: trainB/B (291).png      \n",
      "  inflating: trainB/B (292).png      \n",
      "  inflating: trainB/B (293).png      \n",
      "  inflating: trainB/B (294).png      \n",
      "  inflating: trainB/B (295).png      \n",
      "  inflating: trainB/B (296).png      \n",
      "  inflating: trainB/B (297).png      \n",
      "  inflating: trainB/B (298).png      \n",
      "  inflating: trainB/B (299).png      \n",
      "  inflating: trainB/B (3).png        \n",
      "  inflating: trainB/B (30).png       \n",
      "  inflating: trainB/B (300).png      \n",
      "  inflating: trainB/B (301).png      \n",
      "  inflating: trainB/B (302).png      \n",
      "  inflating: trainB/B (303).png      \n",
      "  inflating: trainB/B (304).png      \n",
      "  inflating: trainB/B (305).png      \n",
      "  inflating: trainB/B (306).png      \n",
      "  inflating: trainB/B (307).png      \n",
      "  inflating: trainB/B (308).png      \n",
      "  inflating: trainB/B (309).png      \n",
      "  inflating: trainB/B (31).png       \n",
      "  inflating: trainB/B (310).png      \n",
      "  inflating: trainB/B (311).png      \n",
      "  inflating: trainB/B (312).png      \n",
      "  inflating: trainB/B (313).png      \n",
      "  inflating: trainB/B (314).png      \n",
      "  inflating: trainB/B (315).png      \n",
      "  inflating: trainB/B (316).png      \n",
      "  inflating: trainB/B (317).png      \n",
      "  inflating: trainB/B (318).png      \n",
      "  inflating: trainB/B (319).png      \n",
      "  inflating: trainB/B (32).png       \n",
      "  inflating: trainB/B (320).png      \n",
      "  inflating: trainB/B (321).png      \n",
      "  inflating: trainB/B (322).png      \n",
      "  inflating: trainB/B (323).png      \n",
      "  inflating: trainB/B (324).png      \n",
      "  inflating: trainB/B (325).png      \n",
      "  inflating: trainB/B (326).png      \n",
      "  inflating: trainB/B (327).png      \n",
      "  inflating: trainB/B (328).png      \n",
      "  inflating: trainB/B (329).png      \n",
      "  inflating: trainB/B (33).png       \n",
      "  inflating: trainB/B (330).png      \n",
      "  inflating: trainB/B (331).png      \n",
      "  inflating: trainB/B (332).png      \n",
      "  inflating: trainB/B (333).png      \n",
      "  inflating: trainB/B (334).png      \n",
      "  inflating: trainB/B (335).png      \n",
      "  inflating: trainB/B (336).png      \n",
      "  inflating: trainB/B (337).png      \n",
      "  inflating: trainB/B (338).png      \n",
      "  inflating: trainB/B (339).png      \n",
      "  inflating: trainB/B (34).png       \n",
      "  inflating: trainB/B (340).png      \n",
      "  inflating: trainB/B (341).png      \n",
      "  inflating: trainB/B (342).png      \n",
      "  inflating: trainB/B (343).png      \n",
      "  inflating: trainB/B (344).png      \n",
      "  inflating: trainB/B (345).png      \n",
      "  inflating: trainB/B (346).png      \n",
      "  inflating: trainB/B (347).png      \n",
      "  inflating: trainB/B (348).png      \n",
      "  inflating: trainB/B (349).png      \n",
      "  inflating: trainB/B (35).png       \n",
      "  inflating: trainB/B (350).png      \n",
      "  inflating: trainB/B (351).png      \n",
      "  inflating: trainB/B (352).png      \n",
      "  inflating: trainB/B (353).png      \n",
      "  inflating: trainB/B (354).png      \n",
      "  inflating: trainB/B (355).png      \n",
      "  inflating: trainB/B (356).png      \n",
      "  inflating: trainB/B (357).png      \n",
      "  inflating: trainB/B (358).png      \n",
      "  inflating: trainB/B (359).png      \n",
      "  inflating: trainB/B (36).png       \n",
      "  inflating: trainB/B (360).png      \n",
      "  inflating: trainB/B (361).png      \n",
      "  inflating: trainB/B (362).png      \n",
      "  inflating: trainB/B (363).png      \n",
      "  inflating: trainB/B (364).png      \n",
      "  inflating: trainB/B (365).png      \n",
      "  inflating: trainB/B (366).png      \n",
      "  inflating: trainB/B (367).png      \n",
      "  inflating: trainB/B (368).png      \n",
      "  inflating: trainB/B (369).png      \n",
      "  inflating: trainB/B (37).png       \n",
      "  inflating: trainB/B (370).png      \n",
      "  inflating: trainB/B (371).png      \n",
      "  inflating: trainB/B (372).png      \n",
      "  inflating: trainB/B (373).png      \n",
      "  inflating: trainB/B (374).png      \n",
      "  inflating: trainB/B (375).png      \n",
      "  inflating: trainB/B (376).png      \n",
      "  inflating: trainB/B (377).png      \n",
      "  inflating: trainB/B (378).png      \n",
      "  inflating: trainB/B (379).png      \n",
      "  inflating: trainB/B (38).png       \n",
      "  inflating: trainB/B (380).png      \n",
      "  inflating: trainB/B (381).png      \n",
      "  inflating: trainB/B (382).png      \n",
      "  inflating: trainB/B (383).png      \n",
      "  inflating: trainB/B (384).png      \n",
      "  inflating: trainB/B (385).png      \n",
      "  inflating: trainB/B (386).png      \n",
      "  inflating: trainB/B (387).png      \n",
      "  inflating: trainB/B (388).png      \n",
      "  inflating: trainB/B (389).png      \n",
      "  inflating: trainB/B (39).png       \n",
      "  inflating: trainB/B (390).png      \n",
      "  inflating: trainB/B (391).png      \n",
      "  inflating: trainB/B (392).png      \n",
      "  inflating: trainB/B (393).png      \n",
      "  inflating: trainB/B (394).png      \n",
      "  inflating: trainB/B (395).png      \n",
      "  inflating: trainB/B (396).png      \n",
      "  inflating: trainB/B (397).png      \n",
      "  inflating: trainB/B (398).png      \n",
      "  inflating: trainB/B (399).png      \n",
      "  inflating: trainB/B (4).png        \n",
      "  inflating: trainB/B (40).png       \n",
      "  inflating: trainB/B (400).png      \n",
      "  inflating: trainB/B (41).png       \n",
      "  inflating: trainB/B (42).png       \n",
      "  inflating: trainB/B (43).png       \n",
      "  inflating: trainB/B (44).png       \n",
      "  inflating: trainB/B (45).png       \n",
      "  inflating: trainB/B (46).png       \n",
      "  inflating: trainB/B (47).png       \n",
      "  inflating: trainB/B (48).png       \n",
      "  inflating: trainB/B (49).png       \n",
      "  inflating: trainB/B (5).png        \n",
      "  inflating: trainB/B (50).png       \n",
      "  inflating: trainB/B (51).png       \n",
      "  inflating: trainB/B (52).png       \n",
      "  inflating: trainB/B (53).png       \n",
      "  inflating: trainB/B (54).png       \n",
      "  inflating: trainB/B (55).png       \n",
      "  inflating: trainB/B (56).png       \n",
      "  inflating: trainB/B (57).png       \n",
      "  inflating: trainB/B (58).png       \n",
      "  inflating: trainB/B (59).png       \n",
      "  inflating: trainB/B (6).png        \n",
      "  inflating: trainB/B (60).png       \n",
      "  inflating: trainB/B (61).png       \n",
      "  inflating: trainB/B (62).png       \n",
      "  inflating: trainB/B (63).png       \n",
      "  inflating: trainB/B (64).png       \n",
      "  inflating: trainB/B (65).png       \n",
      "  inflating: trainB/B (66).png       \n",
      "  inflating: trainB/B (67).png       \n",
      "  inflating: trainB/B (68).png       \n",
      "  inflating: trainB/B (69).png       \n",
      "  inflating: trainB/B (7).png        \n",
      "  inflating: trainB/B (70).png       \n",
      "  inflating: trainB/B (71).png       \n",
      "  inflating: trainB/B (72).png       \n",
      "  inflating: trainB/B (73).png       \n",
      "  inflating: trainB/B (74).png       \n",
      "  inflating: trainB/B (75).png       \n",
      "  inflating: trainB/B (76).png       \n",
      "  inflating: trainB/B (77).png       \n",
      "  inflating: trainB/B (78).png       \n",
      "  inflating: trainB/B (79).png       \n",
      "  inflating: trainB/B (8).png        \n",
      "  inflating: trainB/B (80).png       \n",
      "  inflating: trainB/B (81).png       \n",
      "  inflating: trainB/B (82).png       \n",
      "  inflating: trainB/B (83).png       \n",
      "  inflating: trainB/B (84).png       \n",
      "  inflating: trainB/B (85).png       \n",
      "  inflating: trainB/B (86).png       \n",
      "  inflating: trainB/B (87).png       \n",
      "  inflating: trainB/B (88).png       \n",
      "  inflating: trainB/B (89).png       \n",
      "  inflating: trainB/B (9).png        \n",
      "  inflating: trainB/B (90).png       \n",
      "  inflating: trainB/B (91).png       \n",
      "  inflating: trainB/B (92).png       \n",
      "  inflating: trainB/B (93).png       \n",
      "  inflating: trainB/B (94).png       \n",
      "  inflating: trainB/B (95).png       \n",
      "  inflating: trainB/B (96).png       \n",
      "  inflating: trainB/B (97).png       \n",
      "  inflating: trainB/B (98).png       \n",
      "  inflating: trainB/B (99).png       \n"
     ]
    }
   ],
   "source": [
    "##mindspore版本直接使用大模型平台环境里的2.7\n",
    "##数据集由于下载链接已经失效，手动上传dataset.zip文件，然后解压\n",
    "!unzip dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 指定参数\n",
    "设置案例所需参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"get args.\"\"\"\n",
    "\n",
    "import argparse\n",
    "import ast\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Cycle GAN')\n",
    "\n",
    "# basic parameters\n",
    "parser.add_argument('--platform', type=str, default='Ascend', help='support GPU and Ascend, and CPU')\n",
    "parser.add_argument('--device_id', type=int, default=0, help='device id, default is 0.')\n",
    "parser.add_argument('--device_num', type=int, default=1, help='device num, default is 1.')\n",
    "parser.add_argument('--is_save_on_master', type=int, default=1,\n",
    "                    help='Save ckpt on master or all rank, 1 for master, 0 for all ranks. Default: 1')\n",
    "parser.add_argument('--rank', type=int, default=0, help='Local rank of distributed. Default: 0')\n",
    "parser.add_argument('--group_size', type=int, default=1, help='World size of device. Default: 1')\n",
    "parser.add_argument('--model', type=str, default='ResNet', choices=('DepthResNet', 'ResNet', 'UNet'), \\\n",
    "                    help='generator model')\n",
    "parser.add_argument('--init_type', type=str, default='normal', choices=('normal', 'xavier'), \\\n",
    "                    help='network initialization, default is normal.')\n",
    "parser.add_argument('--init_gain', type=float, default=0.02, \\\n",
    "                    help='scaling factor for normal, xavier and orthogonal, default is 0.02.')\n",
    "parser.add_argument('--image_size', type=int, default=256, help='input image_size, default is 256.')\n",
    "parser.add_argument('--batch_size', type=int, default=1, help='batch_size, default is 1.')\n",
    "parser.add_argument('--pool_size', type=int, default=50, \\\n",
    "                     help='the size of image buffer that stores previously generated images')\n",
    "parser.add_argument('--beta1', type=float, default=0.5, help='Adam beta1, default is 0.5.')\n",
    "parser.add_argument('--lr', type=float, default=0.0002, help='learning rate, default is 0.0002.')\n",
    "parser.add_argument('--lr_policy', type=str, default='linear', choices=('linear', 'constant'), \\\n",
    "                    help='learning rate policy, default is linear')\n",
    "parser.add_argument('--max_epoch', type=int, default=200, help='epoch size for training, default is 200.')\n",
    "parser.add_argument('--n_epochs', type=int, default=100, \\\n",
    "                    help='number of epochs with the initial learning rate, default is 100')\n",
    "\n",
    "# model parameters\n",
    "parser.add_argument('--in_planes', type=int, default=3, help='input channels, default is 3.')\n",
    "parser.add_argument('--ngf', type=int, default=64, help='generator model filter numbers, default is 64.')\n",
    "parser.add_argument('--gl_num', type=int, default=9, help='generator model residual block numbers, default is 9.')\n",
    "parser.add_argument('--ndf', type=int, default=64, help='discriminator model filter numbers, default is 64.')\n",
    "parser.add_argument('--dl_num', type=int, default=3, \\\n",
    "                    help='discriminator model residual block numbers, default is 3.')\n",
    "parser.add_argument('--slope', type=float, default=0.2, help='leakyrelu slope, default is 0.2.')\n",
    "parser.add_argument('--norm_mode', type=str, default='batch', choices=('batch', 'instance'), \\\n",
    "                    help='norm mode, default is batch.')\n",
    "parser.add_argument('--lambda_A', type=float, default=10.0, \\\n",
    "                    help='weight for cycle loss (A -> B -> A), default is 10.')\n",
    "parser.add_argument('--lambda_B', type=float, default=10.0, \\\n",
    "                    help='weight for cycle loss (B -> A -> B), default is 10.')\n",
    "parser.add_argument('--lambda_idt', type=float, default=0.5, \\\n",
    "                    help='use identity mapping. Setting lambda_identity other than 0 has an effect of scaling the '\n",
    "                         'weight of the identity mapping loss. For example, if the weight of the identity loss '\n",
    "                         'should be 10 times smaller than the weight of the reconstruction loss,'\n",
    "                         'please set lambda_identity = 0.1, default is 0.5.')\n",
    "parser.add_argument('--gan_mode', type=str, default='lsgan', choices=('lsgan', 'vanilla'), \\\n",
    "                    help='the type of GAN loss, default is lsgan.')\n",
    "parser.add_argument('--pad_mode', type=str, default='CONSTANT', choices=('CONSTANT', 'REFLECT', 'SYMMETRIC'), \\\n",
    "                    help='the type of Pad, default is CONSTANT.')\n",
    "\n",
    "# additional parameters\n",
    "parser.add_argument('--dataroot', default='./data/dataset/', \\\n",
    "                    help='path of images (should have subfolders trainA, trainB, testA, testB, etc).')\n",
    "parser.add_argument('--data_dir', default='testA', choices=('testA', 'testB'), \\\n",
    "                    help='the translation direction of CycleGAN.')\n",
    "parser.add_argument('--outputs_dir', type=str, default='./outputs', \\\n",
    "                    help='models are saved here, default is ./outputs.')\n",
    "parser.add_argument('--load_ckpt', type=ast.literal_eval, default=False, \\\n",
    "                    help='whether load pretrained ckpt')\n",
    "parser.add_argument('--G_A_ckpt', type=str, default='./outputs/ckpt/G_A_200.ckpt', \\\n",
    "                    help='checkpoint file path of G_A.')\n",
    "parser.add_argument('--G_B_ckpt', type=str, default='./outputs/ckpt/G_B_200.ckpt', \\\n",
    "                    help='checkpoint file path of G_B.')\n",
    "parser.add_argument('--D_A_ckpt', type=str, default='./outputs/ckpt/D_A_200.ckpt', \\\n",
    "                    help='checkpoint file path of D_A.')\n",
    "parser.add_argument('--D_B_ckpt', type=str, default='./outputs/ckpt/D_B_200.ckpt', \\\n",
    "                    help='checkpoint file path of D_B.')\n",
    "parser.add_argument('--save_checkpoint_epochs', type=int, default=10, \\\n",
    "                    help='Save checkpoint epochs, default is 10.')\n",
    "parser.add_argument('--print_iter', type=int, default=100, help='log print iter, default is 100.')\n",
    "parser.add_argument('--need_profiler', type=ast.literal_eval, default=False, \\\n",
    "                    help='whether need profiler, default is False.')\n",
    "parser.add_argument('--save_graphs', type=ast.literal_eval, default=False, \\\n",
    "                    help='whether save graphs, default is False.')\n",
    "parser.add_argument('--save_imgs', type=ast.literal_eval, default=True, \\\n",
    "                    help='whether save imgs when epoch end')\n",
    "parser.add_argument('--save_img_nums', type=int, default=3, \\\n",
    "                    help='Save img nums when epoch end')\n",
    "parser.add_argument('--use_random', type=ast.literal_eval, default=True, \\\n",
    "                    help='whether use random when training, default is True.')\n",
    "parser.add_argument('--need_dropout', type=ast.literal_eval, default=False, \\\n",
    "                    help='whether need dropout, default is True.')\n",
    "parser.add_argument('--max_dataset_size', type=int, default=None, \\\n",
    "                    help='max images pre epoch, default is None.')\n",
    "\n",
    "# export parameters\n",
    "parser.add_argument(\"--export_batch_size\", type=int, default=1, \\\n",
    "                    help=\"batch size\")\n",
    "parser.add_argument(\"--export_file_name\", type=str, default=\"CycleGAN\", \\\n",
    "                    help=\"output file name.\")\n",
    "parser.add_argument(\"--export_file_format\", type=str, choices=[\"AIR\", \"ONNX\", \"MINDIR\"], \\\n",
    "                    default='MINDIR', help=\"file format\")\n",
    "# args = parser.parse_args()\n",
    "args = parser.parse_args(args=[]) # run .ipynb use this\n",
    "\n",
    "\n",
    "def get_args(phase):\n",
    "    \"\"\"Define the common options that are used in both training and test.\"\"\"\n",
    "    if args.platform == \"Ascend\":\n",
    "        args.pad_mode = \"CONSTANT\"\n",
    "\n",
    "    if phase != \"train\" and (args.G_A_ckpt is None or args.G_B_ckpt is None):\n",
    "        raise ValueError('Must set G_A_ckpt and G_B_ckpt in predict phase!')\n",
    "\n",
    "    if args.batch_size == 1:\n",
    "        args.norm_mode = \"instance\"\n",
    "\n",
    "    if args.dataroot is None:\n",
    "        raise ValueError('Must set dataroot!')\n",
    "\n",
    "    if args.max_dataset_size is None:\n",
    "        args.max_dataset_size = float(\"inf\")\n",
    "\n",
    "    args.n_epochs = min(args.max_epoch, args.n_epochs)\n",
    "    args.n_epochs_decay = args.max_epoch - args.n_epochs\n",
    "    args.phase = phase\n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集加载\n",
    "\n",
    "使用 MindSpore 的 `GeneratorDataset` 接口读取和解析数据集。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"Dataset distributed sampler.\"\"\"\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class DistributedSampler:\n",
    "    \"\"\"Distributed sampler.\"\"\"\n",
    "    def __init__(self, dataset_size, num_replicas=None, rank=None, shuffle=True):\n",
    "        if num_replicas is None:\n",
    "            print(\"***********Setting world_size to 1 since it is not passed in ******************\")\n",
    "            num_replicas = 1\n",
    "        if rank is None:\n",
    "            print(\"***********Setting rank to 0 since it is not passed in ******************\")\n",
    "            rank = 0\n",
    "        self.dataset_size = dataset_size\n",
    "        self.num_replicas = num_replicas\n",
    "        self.rank = rank\n",
    "        self.epoch = 0\n",
    "        self.num_samples = int(math.ceil(dataset_size * 1.0 / self.num_replicas))\n",
    "        self.total_size = self.num_samples * self.num_replicas\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        # deterministically shuffle based on epoch\n",
    "        if self.shuffle:\n",
    "            indices = np.random.RandomState(seed=self.epoch).permutation(self.dataset_size)\n",
    "            # np.array type. number from 0 to len(dataset_size)-1, used as index of dataset\n",
    "            indices = indices.tolist()\n",
    "            self.epoch += 1\n",
    "            # change to list type\n",
    "        else:\n",
    "            indices = list(range(self.dataset_size))\n",
    "\n",
    "        # add extra samples to make it evenly divisible\n",
    "        indices += indices[:(self.total_size - len(indices))]\n",
    "        assert len(indices) == self.total_size\n",
    "\n",
    "        # subsample\n",
    "        indices = indices[self.rank:self.total_size:self.num_replicas]\n",
    "        assert len(indices) == self.num_samples\n",
    "\n",
    "        return iter(indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "\n",
    "\"\"\"Cycle GAN dataset.\"\"\"\n",
    "\n",
    "import os\n",
    "import random\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import mindspore.dataset as de\n",
    "import mindspore.dataset.vision as C\n",
    "\n",
    "IMG_EXTENSIONS = ['.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.tif', '.tiff']\n",
    "\n",
    "def is_image_file(filename):\n",
    "    \"\"\"Judge whether it is a picture.\"\"\"\n",
    "    return any(filename.lower().endswith(extension) for extension in IMG_EXTENSIONS)\n",
    "\n",
    "\n",
    "def make_dataset(dir_path, max_dataset_size=float(\"inf\")):\n",
    "    \"\"\"Return image list in dir.\"\"\"\n",
    "    images = []\n",
    "    assert os.path.isdir(dir_path), '%s is not a valid directory' % dir_path\n",
    "\n",
    "    for root, _, fnames in sorted(os.walk(dir_path)):\n",
    "        for fname in fnames:\n",
    "            if is_image_file(fname):\n",
    "                path = os.path.join(root, fname)\n",
    "                images.append(path)\n",
    "    return images[:min(max_dataset_size, len(images))]\n",
    "\n",
    "\n",
    "class UnalignedDataset:\n",
    "    \"\"\"\n",
    "    This dataset class can load unaligned/unpaired datasets.\n",
    "    It requires two directories to host training images from domain A '/path/to/data/trainA'\n",
    "    and from domain B '/path/to/data/trainB' respectively.\n",
    "    You can train the model with the dataset flag '--dataroot /path/to/data'.\n",
    "    Similarly, you need to prepare two directories:\n",
    "    '/path/to/data/testA' and '/path/to/data/testB' during test time.\n",
    "    Returns:\n",
    "        Two domain image path list.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataroot, phase, max_dataset_size=float(\"inf\"), use_random=True):\n",
    "        self.dir_A = os.path.join(dataroot, phase + 'A')\n",
    "        self.dir_B = os.path.join(dataroot, phase + 'B')\n",
    "\n",
    "        self.A_paths = sorted(make_dataset(self.dir_A, max_dataset_size))   # load images from '/path/to/data/trainA'\n",
    "        self.B_paths = sorted(make_dataset(self.dir_B, max_dataset_size))    # load images from '/path/to/data/trainB'\n",
    "        self.A_size = len(self.A_paths)  # get the size of dataset A\n",
    "        self.B_size = len(self.B_paths)  # get the size of dataset B\n",
    "        self.use_random = use_random\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Return a data point and its metadata information.\n",
    "\n",
    "        Parameters:\n",
    "            index (int)      -- a random integer for data indexing\n",
    "\n",
    "        Returns a dictionary that contains A, B, A_paths and B_paths\n",
    "            A (tensor)       -- an image in the input domain\n",
    "            B (tensor)       -- its corresponding image in the target domain\n",
    "            A_paths (str)    -- image paths\n",
    "            B_paths (str)    -- image paths\n",
    "        \"\"\"\n",
    "        index_B = index % self.B_size\n",
    "        if index % max(self.A_size, self.B_size) == 0 and self.use_random:\n",
    "            random.shuffle(self.A_paths)\n",
    "            index_B = random.randint(0, self.B_size - 1)\n",
    "        A_path = self.A_paths[index % self.A_size]\n",
    "        B_path = self.B_paths[index_B]\n",
    "        A_img = np.array(Image.open(A_path).convert('RGB'))\n",
    "        B_img = np.array(Image.open(B_path).convert('RGB'))\n",
    "\n",
    "        return A_img, B_img\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the total number of images in the dataset.\n",
    "        \"\"\"\n",
    "        # return max(self.A_size, self.B_size)\n",
    "        return self.A_size\n",
    "\n",
    "\n",
    "class ImageFolderDataset:\n",
    "    \"\"\"\n",
    "    This dataset class can load images from image folder.\n",
    "    Args:\n",
    "        dataroot (str): Images root directory.\n",
    "        max_dataset_size (int): Maximum number of return image paths.\n",
    "    Returns:\n",
    "        Image path list.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataroot, max_dataset_size=float(\"inf\")):\n",
    "        self.dataroot = dataroot\n",
    "        self.paths = sorted(make_dataset(dataroot, max_dataset_size))\n",
    "        self.size = len(self.paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.paths[index % self.size]\n",
    "        img = np.array(Image.open(img_path).convert('RGB'))\n",
    "\n",
    "        return img, os.path.split(img_path)[1]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the total number of images in the dataset.\n",
    "        As we have two datasets with potentially different number of images,\n",
    "        we take a maximum of\n",
    "        \"\"\"\n",
    "        return self.size\n",
    "\n",
    "\n",
    "def create_dataset(args):\n",
    "    \"\"\"\n",
    "    Create dataset\n",
    "    This dataset class can load images for train or test.\n",
    "    Args:\n",
    "        dataroot (str): Images root directory.\n",
    "    Returns:\n",
    "        RGB Image list.\n",
    "    \"\"\"\n",
    "    dataroot = args.dataroot\n",
    "    phase = args.phase\n",
    "    batch_size = args.batch_size\n",
    "    device_num = args.device_num\n",
    "    rank = args.rank\n",
    "    shuffle = args.use_random\n",
    "    max_dataset_size = args.max_dataset_size\n",
    "    cores = multiprocessing.cpu_count()\n",
    "    num_parallel_workers = 1\n",
    "    # num_parallel_workers = min(8, int(cores / device_num))\n",
    "    image_size = args.image_size\n",
    "    mean = [0.5 * 255] * 3\n",
    "    std = [0.5 * 255] * 3\n",
    "    if phase == \"train\":\n",
    "        dataset = UnalignedDataset(dataroot, phase, max_dataset_size=max_dataset_size, use_random=args.use_random)\n",
    "        distributed_sampler = DistributedSampler(len(dataset), device_num, rank, shuffle=shuffle)\n",
    "        ds = de.GeneratorDataset(dataset, column_names=[\"image_A\", \"image_B\"],\n",
    "                                 sampler=distributed_sampler, num_parallel_workers=num_parallel_workers)\n",
    "        if args.use_random:\n",
    "            trans = [\n",
    "                # C.RandomResizedCrop(image_size, scale=(0.5, 1.0), ratio=(0.75, 1.333)),\n",
    "                # C.RandomHorizontalFlip(prob=0.5),\n",
    "                C.RandomResizedCrop(image_size, scale=(1.0, 1.0), ratio=(1.0, 1.0)),\n",
    "                C.RandomHorizontalFlip(prob=0),\n",
    "                C.Normalize(mean=mean, std=std),\n",
    "                C.HWC2CHW()\n",
    "            ]\n",
    "        else:\n",
    "            trans = [\n",
    "                C.Resize((image_size, image_size)),\n",
    "                C.Normalize(mean=mean, std=std),\n",
    "                C.HWC2CHW()\n",
    "            ]\n",
    "        ds = ds.map(operations=trans, input_columns=[\"image_A\"], num_parallel_workers=num_parallel_workers)\n",
    "        ds = ds.map(operations=trans, input_columns=[\"image_B\"], num_parallel_workers=num_parallel_workers)\n",
    "        ds = ds.batch(batch_size, drop_remainder=True)\n",
    "    else:\n",
    "        datadir = os.path.join(dataroot, args.data_dir)\n",
    "        dataset = ImageFolderDataset(datadir, max_dataset_size=max_dataset_size)\n",
    "        ds = de.GeneratorDataset(dataset, column_names=[\"image\", \"image_name\"],\n",
    "                                 num_parallel_workers=num_parallel_workers)\n",
    "        trans = [\n",
    "            C.Resize((image_size, image_size)),\n",
    "            C.Normalize(mean=mean, std=std),\n",
    "            C.HWC2CHW()\n",
    "        ]\n",
    "        ds = ds.map(operations=trans, input_columns=[\"image\"], num_parallel_workers=num_parallel_workers)\n",
    "        ds = ds.batch(1, drop_remainder=True)\n",
    "    args.dataset_size = len(dataset)\n",
    "    return ds\n",
    "\n",
    "\n",
    "import mindspore as ms\n",
    "from mindspore.communication import init, get_rank, get_group_size\n",
    "\n",
    "args = get_args(\"train\")\n",
    "args.batch_size = 1\n",
    "args.dataroot = './'\n",
    "\n",
    "if args.device_num > 1:\n",
    "    ms.set_context(mode=ms.GRAPH_MODE, device_target=args.platform, save_graphs=args.save_graphs)\n",
    "    init()\n",
    "    ms.reset_auto_parallel_context()\n",
    "    ms.set_auto_parallel_context(parallel_mode=ms.ParallelMode.DATA_PARALLEL, gradients_mean=True)\n",
    "    args.rank = get_rank()\n",
    "    args.group_size = get_group_size()\n",
    "else:\n",
    "    ms.set_context(mode=ms.GRAPH_MODE, device_target=args.platform,\n",
    "                   save_graphs=args.save_graphs, device_id=args.device_id)\n",
    "    args.rank = 0\n",
    "    args.device_num = 1\n",
    "\n",
    "if args.platform == \"GPU\":\n",
    "    ms.set_context(enable_graph_kernel=True)\n",
    "if args.need_profiler:\n",
    "    from mindspore.profiler.profiling import Profiler\n",
    "    profiler = Profiler(output_path=args.outputs_dir, is_detail=True, is_show_op_path=True)\n",
    "\n",
    "ds = create_dataset(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可视化\n",
    "\n",
    "通过 `create_dict_iterator` 函数将数据转换成字典迭代器，然后使用 `matplotlib` 模块可视化部分训练数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x300 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mean = 0.5 * 255\n",
    "std = 0.5 * 255\n",
    "\n",
    "plt.figure(figsize=(12, 5), dpi=60)\n",
    "for i, data in enumerate(ds.create_dict_iterator()):\n",
    "    if i < 5:\n",
    "        show_images_a = data[\"image_A\"].asnumpy()\n",
    "        show_images_b = data[\"image_B\"].asnumpy()\n",
    "\n",
    "        plt.subplot(2, 5, i+1)\n",
    "        show_images_a = (show_images_a[0] * std + mean).astype(np.uint8).transpose((1, 2, 0))\n",
    "        plt.imshow(show_images_a)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(2, 5, i+6)\n",
    "        show_images_b = (show_images_b[0] * std + mean).astype(np.uint8).transpose((1, 2, 0))\n",
    "        plt.imshow(show_images_b)\n",
    "        plt.axis(\"off\")\n",
    "    else:\n",
    "        break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 构建生成器\n",
    "\n",
    "本案例生成器的模型结构参考的 ResNet 模型的结构，参考原论文，对于128×128大小的输入图片采用6个残差块相连，图片大小为256×256以上的需要采用9个残差块相连，所以本文网络有9个残差块相连，超参数 `n_layers` 参数控制残差块数。\n",
    "\n",
    "生成器的结构如下所示：\n",
    "\n",
    "![CycleGAN Generator](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.3.0rc2/tutorials/application/source_zh_cn/generative/images/CycleGAN_2.jpg)\n",
    "\n",
    "具体的模型结构请参照下文代码：\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 上采样模块\n",
    "\n",
    "构建`ConvNormReLU`和`ConvTransposeNormReLU`部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"Cycle GAN network.\"\"\"\n",
    "\n",
    "from mindspore import nn\n",
    "from mindspore.common.initializer import initializer, Normal, XavierUniform\n",
    "\n",
    "\n",
    "def init_weights(net, init_type='normal', init_gain=0.02):\n",
    "    \"\"\"\n",
    "    Initialize network weights.\n",
    "    Parameters:\n",
    "        net (Cell): Network to be initialized\n",
    "        init_type (str): The name of an initialization method: normal | xavier.\n",
    "        init_gain (float): Gain factor for normal and xavier.\n",
    "    \"\"\"\n",
    "    for _, cell in net.cells_and_names():\n",
    "        if isinstance(cell, (nn.Conv2d, nn.Conv2dTranspose)):\n",
    "            if init_type == 'normal':\n",
    "                cell.weight.set_data(initializer(Normal(init_gain), cell.weight.shape, cell.weight.dtype))\n",
    "            elif init_type == 'xavier':\n",
    "                cell.weight.set_data(initializer(XavierUniform(init_gain), cell.weight.shape, cell.weight.dtype))\n",
    "            elif init_type == 'constant':\n",
    "                cell.weight.set_data(initializer(0.001, cell.weight.shape, cell.weight.dtype))\n",
    "            else:\n",
    "                raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n",
    "        elif isinstance(cell, nn.BatchNorm2d):\n",
    "            cell.gamma.set_data(initializer('ones', cell.gamma.shape, cell.gamma.dtype))\n",
    "            cell.beta.set_data(initializer('zeros', cell.beta.shape, cell.beta.dtype))\n",
    "\n",
    "\n",
    "class ConvNormReLU(nn.Cell):\n",
    "    \"\"\"\n",
    "    Convolution fused with BatchNorm/InstanceNorm and ReLU/LackyReLU block definition.\n",
    "    Args:\n",
    "        in_planes (int): Input channel.\n",
    "        out_planes (int): Output channel.\n",
    "        kernel_size (int): Input kernel size. Default: 4.\n",
    "        stride (int): Stride size for the first convolutional layer. Default: 2.\n",
    "        alpha (float): Slope of LackyReLU. Default: 0.2.\n",
    "        norm_mode (str): Specifies norm method. The optional values are \"batch\", \"instance\".\n",
    "        pad_mode (str): Specifies padding mode. The optional values are \"CONSTANT\", \"REFLECT\", \"SYMMETRIC\".\n",
    "            Default: \"CONSTANT\".\n",
    "        use_relu (bool): Use relu or not. Default: True.\n",
    "        padding (int): Pad size, if it is None, it will calculate by kernel_size. Default: None.\n",
    "    Returns:\n",
    "        Tensor, output tensor.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_planes,\n",
    "                 out_planes,\n",
    "                 kernel_size=4,\n",
    "                 stride=2,\n",
    "                 alpha=0.2,\n",
    "                 norm_mode='batch',\n",
    "                 pad_mode='CONSTANT',\n",
    "                 use_relu=True,\n",
    "                 padding=None):\n",
    "        super(ConvNormReLU, self).__init__()\n",
    "        norm = nn.BatchNorm2d(out_planes)\n",
    "        if norm_mode == 'instance':\n",
    "            # Use BatchNorm2d with batchsize=1, affine=False, training=True instead of InstanceNorm2d\n",
    "            norm = nn.BatchNorm2d(out_planes, affine=False)\n",
    "        has_bias = (norm_mode == 'instance')\n",
    "        if padding is None:\n",
    "            padding = (kernel_size - 1) // 2\n",
    "        if pad_mode == 'CONSTANT':\n",
    "            conv = nn.Conv2d(in_planes, out_planes, kernel_size, stride, pad_mode='pad',\n",
    "                             has_bias=has_bias, padding=padding)\n",
    "            layers = [conv, norm]\n",
    "        else:\n",
    "            paddings = ((0, 0), (0, 0), (padding, padding), (padding, padding))\n",
    "            pad = nn.Pad(paddings=paddings, mode=pad_mode)\n",
    "            conv = nn.Conv2d(in_planes, out_planes, kernel_size, stride, pad_mode='pad', has_bias=has_bias)\n",
    "            layers = [pad, conv, norm]\n",
    "        if use_relu:\n",
    "            relu = nn.ReLU()\n",
    "            if alpha > 0:\n",
    "                relu = nn.LeakyReLU(alpha)\n",
    "            layers.append(relu)\n",
    "        self.features = nn.SequentialCell(layers)\n",
    "\n",
    "    def construct(self, x):\n",
    "        output = self.features(x)\n",
    "        return output\n",
    "\n",
    "\n",
    "class ConvTransposeNormReLU(nn.Cell):\n",
    "    \"\"\"\n",
    "    ConvTranspose2d fused with BatchNorm/InstanceNorm and ReLU/LackyReLU block definition.\n",
    "    Args:\n",
    "        in_planes (int): Input channel.\n",
    "        out_planes (int): Output channel.\n",
    "        kernel_size (int): Input kernel size. Default: 4.\n",
    "        stride (int): Stride size for the first convolutional layer. Default: 2.\n",
    "        alpha (float): Slope of LackyReLU. Default: 0.2.\n",
    "        norm_mode (str): Specifies norm method. The optional values are \"batch\", \"instance\".\n",
    "        pad_mode (str): Specifies padding mode. The optional values are \"CONSTANT\", \"REFLECT\", \"SYMMETRIC\".\n",
    "                        Default: \"CONSTANT\".\n",
    "        use_relu (bool): use relu or not. Default: True.\n",
    "        padding (int): pad size, if it is None, it will calculate by kernel_size. Default: None.\n",
    "    Returns:\n",
    "        Tensor, output tensor.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_planes,\n",
    "                 out_planes,\n",
    "                 kernel_size=4,\n",
    "                 stride=2,\n",
    "                 alpha=0.2,\n",
    "                 norm_mode='batch',\n",
    "                 pad_mode='CONSTANT',\n",
    "                 use_relu=True,\n",
    "                 padding=None):\n",
    "        super(ConvTransposeNormReLU, self).__init__()\n",
    "        conv = nn.Conv2dTranspose(in_planes, out_planes, kernel_size, stride=stride, pad_mode='same')\n",
    "        norm = nn.BatchNorm2d(out_planes)\n",
    "        if norm_mode == 'instance':\n",
    "            # Use BatchNorm2d with batchsize=1, affine=False, training=True instead of InstanceNorm2d\n",
    "            norm = nn.BatchNorm2d(out_planes, affine=False)\n",
    "        has_bias = (norm_mode == 'instance')\n",
    "        if padding is None:\n",
    "            padding = (kernel_size - 1) // 2\n",
    "        if pad_mode == 'CONSTANT':\n",
    "            conv = nn.Conv2dTranspose(in_planes, out_planes, kernel_size, stride, pad_mode='same', has_bias=has_bias)\n",
    "            layers = [conv, norm]\n",
    "        else:\n",
    "            paddings = ((0, 0), (0, 0), (padding, padding), (padding, padding))\n",
    "            pad = nn.Pad(paddings=paddings, mode=pad_mode)\n",
    "            conv = nn.Conv2dTranspose(in_planes, out_planes, kernel_size, stride, pad_mode='pad', has_bias=has_bias)\n",
    "            layers = [pad, conv, norm]\n",
    "        if use_relu:\n",
    "            relu = nn.ReLU()\n",
    "            if alpha > 0:\n",
    "                relu = nn.LeakyReLU(alpha)\n",
    "            layers.append(relu)\n",
    "        self.features = nn.SequentialCell(layers)\n",
    "\n",
    "    def construct(self, x):\n",
    "        output = self.features(x)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet\n",
    "\n",
    "构建`ResidualBlock`和`ResNetGenerator`模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"ResNet Generator.\"\"\"\n",
    "\n",
    "from mindspore import nn\n",
    "from mindspore import ops\n",
    "\n",
    "\n",
    "# ResNet\n",
    "class ResidualBlock1(nn.Cell):\n",
    "    \"\"\"\n",
    "    A resnet block is a conv block with skip connections\n",
    "    We construct a conv block with build_conv_block function,\n",
    "    and implement skip connections in <forward> function..\n",
    "    Args:\n",
    "        dim (int): Input and output channel.\n",
    "        norm_mode (str): Specifies norm method. The optional values are \"batch\", \"instance\".\n",
    "        dropout (bool): Use dropout or not. Default: False.\n",
    "        pad_mode (str): Specifies padding mode. The optional values are \"CONSTANT\", \"REFLECT\", \"SYMMETRIC\".\n",
    "            Default: \"CONSTANT\".\n",
    "    Returns:\n",
    "        Tensor, output tensor.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, norm_mode='batch', dropout=False, pad_mode=\"CONSTANT\"):\n",
    "        super(ResidualBlock1, self).__init__()\n",
    "        self.conv1 = ConvNormReLU(dim, dim, 3, 1, 0, norm_mode, pad_mode)\n",
    "        self.conv2 = ConvNormReLU(dim, dim, 3, 1, 0, norm_mode, pad_mode, use_relu=False)\n",
    "        self.dropout = dropout\n",
    "        if dropout:\n",
    "            self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def construct(self, x):\n",
    "        out = self.conv1(x)\n",
    "        if self.dropout:\n",
    "            out = self.dropout(out)\n",
    "        out = self.conv2(out)\n",
    "        return x + out\n",
    "\n",
    "\n",
    "class ResNetGenerator(nn.Cell):\n",
    "    \"\"\"\n",
    "    ResNet Generator of GAN.\n",
    "    Args:\n",
    "        in_planes (int): Input channel.\n",
    "        ngf (int): Output channel.\n",
    "        n_layers (int): The number of ConvNormReLU blocks.\n",
    "        alpha (float): LeakyRelu slope. Default: 0.2.\n",
    "        norm_mode (str): Specifies norm method. The optional values are \"batch\", \"instance\".\n",
    "        dropout (bool): Use dropout or not. Default: False.\n",
    "        pad_mode (str): Specifies padding mode. The optional values are \"CONSTANT\", \"REFLECT\", \"SYMMETRIC\".\n",
    "            Default: \"CONSTANT\".\n",
    "    Returns:\n",
    "        Tensor, output tensor.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_planes=3, ngf=64, n_layers=9, alpha=0.2, norm_mode='batch', dropout=False,\n",
    "                 pad_mode=\"CONSTANT\"):\n",
    "        super(ResNetGenerator, self).__init__()\n",
    "        self.conv_in = ConvNormReLU(in_planes, ngf, 7, 1, alpha, norm_mode, pad_mode=pad_mode)\n",
    "        self.down_1 = ConvNormReLU(ngf, ngf * 2, 3, 2, alpha, norm_mode)\n",
    "        self.down_2 = ConvNormReLU(ngf * 2, ngf * 4, 3, 2, alpha, norm_mode)\n",
    "        layers = [ResidualBlock1(ngf * 4, norm_mode, dropout=dropout, pad_mode=pad_mode)] * n_layers\n",
    "        self.residuals = nn.SequentialCell(layers)\n",
    "        self.up_2 = ConvTransposeNormReLU(ngf * 4, ngf * 2, 3, 2, alpha, norm_mode)\n",
    "        self.up_1 = ConvTransposeNormReLU(ngf * 2, ngf, 3, 2, alpha, norm_mode)\n",
    "        if pad_mode == \"CONSTANT\":\n",
    "            self.conv_out = nn.Conv2d(ngf, 3, kernel_size=7, stride=1, pad_mode='pad', padding=3)\n",
    "        else:\n",
    "            pad = nn.Pad(paddings=((0, 0), (0, 0), (3, 3), (3, 3)), mode=pad_mode)\n",
    "            conv = nn.Conv2d(ngf, 3, kernel_size=7, stride=1, pad_mode='pad')\n",
    "            self.conv_out = nn.SequentialCell([pad, conv])\n",
    "        self.activate = ops.Tanh()\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.conv_in(x)\n",
    "        x = self.down_1(x)\n",
    "        x = self.down_2(x)\n",
    "        x = self.residuals(x)\n",
    "        x = self.up_2(x)\n",
    "        x = self.up_1(x)\n",
    "        output = self.conv_out(x)\n",
    "        return self.activate(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DepthResNet和Unet\n",
    "\n",
    "生成器的模型结构还可以参考`DepthResNet`和`Unet`的结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# DepthResNet\n",
    "class ResidualBlock(nn.Cell):\n",
    "    \"\"\"\n",
    "    ResNet residual block definition.\n",
    "    We construct a conv block with build_conv_block function,\n",
    "    and implement skip connections in <forward> function..\n",
    "    Args:\n",
    "        dim (int): Input and output channel.\n",
    "        norm_mode (str): Specifies norm method. The optional values are \"batch\", \"instance\".\n",
    "        dropout (bool): Use dropout or not. Default: False.\n",
    "        pad_mode (str): Specifies padding mode. The optional values are \"CONSTANT\", \"REFLECT\", \"SYMMETRIC\".\n",
    "            Default: \"CONSTANT\".\n",
    "    Returns:\n",
    "        Tensor, output tensor.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, norm_mode='batch', dropout=False, pad_mode=\"CONSTANT\"):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = ConvNormReLU(dim, dim, 3, 1, 0.2, norm_mode, pad_mode)\n",
    "        self.conv2 = ConvNormReLU(dim, dim, 3, 1, 0.2, norm_mode, pad_mode)\n",
    "        self.dropout = dropout\n",
    "        if dropout:\n",
    "            self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def construct(self, x):\n",
    "        out = self.conv1(x)\n",
    "        if self.dropout:\n",
    "            out = self.dropout(out)\n",
    "        out = self.conv2(out)\n",
    "        return x + out\n",
    "\n",
    "\n",
    "class DepthResNetGenerator(nn.Cell):\n",
    "    \"\"\"\n",
    "    ResNet Generator of GAN.\n",
    "    Args:\n",
    "        in_planes (int): Input channel.\n",
    "        ngf (int): Output channel.\n",
    "        n_layers (int): The number of ConvNormReLU blocks.\n",
    "        alpha (float): LeakyRelu slope. Default: 0.2.\n",
    "        norm_mode (str): Specifies norm method. The optional values are \"batch\", \"instance\".\n",
    "        dropout (bool): Use dropout or not. Default: False.\n",
    "        pad_mode (str): Specifies padding mode. The optional values are \"CONSTANT\", \"REFLECT\", \"SYMMETRIC\".\n",
    "            Default: \"CONSTANT\".\n",
    "    Returns:\n",
    "        Tensor, output tensor.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_planes=3, ngf=64, n_layers=9, alpha=0.2, norm_mode='batch', dropout=False,\n",
    "                 pad_mode=\"CONSTANT\"):\n",
    "        super(DepthResNetGenerator, self).__init__()\n",
    "        conv_in1 = nn.Conv2d(in_planes, ngf, kernel_size=3, stride=1, has_bias=True)\n",
    "        conv_in2 = ConvNormReLU(ngf, ngf, 7, 1, alpha, norm_mode, pad_mode=pad_mode)\n",
    "        self.conv_in = nn.SequentialCell([conv_in1, conv_in2])\n",
    "        down_1 = ConvNormReLU(ngf, ngf * 2, 3, 2, alpha, norm_mode)\n",
    "        Res1 = ResidualBlock(ngf * 2, norm_mode, dropout=dropout, pad_mode=pad_mode)\n",
    "        self.down_1 = nn.SequentialCell([down_1, Res1])\n",
    "        down_2 = ConvNormReLU(ngf * 2, ngf * 3, 3, 2, alpha, norm_mode)\n",
    "        Res2 = ResidualBlock(ngf * 3, norm_mode, dropout=dropout, pad_mode=pad_mode)\n",
    "        self.down_2 = nn.SequentialCell([down_2, Res2])\n",
    "        self.down_3 = ConvNormReLU(ngf * 3, ngf * 4, 3, 2, alpha, norm_mode)\n",
    "        layers = [ResidualBlock(ngf * 4, norm_mode, dropout=dropout, pad_mode=pad_mode)] * (n_layers-5)\n",
    "        self.residuals = nn.SequentialCell(layers)\n",
    "        up_3 = ConvTransposeNormReLU(ngf * 4, ngf * 3, 3, 2, alpha, norm_mode)\n",
    "        Res3 = ResidualBlock(ngf * 3, norm_mode, dropout=dropout, pad_mode=pad_mode)\n",
    "        self.up_3 = nn.SequentialCell([up_3, Res3])\n",
    "        up_2 = ConvTransposeNormReLU(ngf * 3, ngf * 2, 3, 2, alpha, norm_mode)\n",
    "        Res4 = ResidualBlock(ngf * 2, norm_mode, dropout=dropout, pad_mode=pad_mode)\n",
    "        self.up_2 = nn.SequentialCell([up_2, Res4])\n",
    "        up_1 = ConvTransposeNormReLU(ngf * 2, ngf, 3, 2, alpha, norm_mode)\n",
    "        Res5 = ResidualBlock(ngf, norm_mode, dropout=dropout, pad_mode=pad_mode)\n",
    "        self.up_1 = nn.SequentialCell([up_1, Res5])\n",
    "        tanh = nn.Tanh()\n",
    "        if pad_mode == \"CONSTANT\":\n",
    "            conv_out1 = nn.Conv2d(ngf, 3, kernel_size=7, stride=1, has_bias=True, pad_mode='pad', padding=3)\n",
    "            conv_out2 = nn.Conv2d(3, 3, kernel_size=3, stride=1, has_bias=True)\n",
    "            self.conv_out = nn.SequentialCell([conv_out1, tanh, conv_out2, tanh])\n",
    "        else:\n",
    "            pad = nn.Pad(paddings=((0, 0), (0, 0), (3, 3), (3, 3)), mode=pad_mode)\n",
    "            conv = nn.Conv2d(ngf, 3, kernel_size=7, stride=1, pad_mode='pad')\n",
    "            self.conv_out = nn.SequentialCell([pad, conv, tanh])\n",
    "\n",
    "    def construct(self, x):\n",
    "        \"\"\" construct network \"\"\"\n",
    "        x = self.conv_in(x)\n",
    "        x = self.down_1(x)\n",
    "        x = self.down_2(x)\n",
    "        x = self.down_3(x)\n",
    "        x = self.residuals(x)\n",
    "        x = self.up_3(x)\n",
    "        x = self.up_2(x)\n",
    "        x = self.up_1(x)\n",
    "        output = self.conv_out(x)\n",
    "        return output\n",
    "\n",
    "\n",
    "# Unet\n",
    "class UnetGenerator(nn.Cell):\n",
    "    \"\"\"\n",
    "    Unet-based generator.\n",
    "\n",
    "    Args:\n",
    "        in_planes (int): the number of channels in input images.\n",
    "        out_planes (int): the number of channels in output images.\n",
    "        ngf (int): the number of filters in the last conv layer.\n",
    "        n_layers (int): the number of downsamplings in UNet.\n",
    "        alpha (float): LeakyRelu slope. Default: 0.2.\n",
    "        norm_mode (str): Specifies norm method. The optional values are \"batch\", \"instance\".\n",
    "        dropout (bool): Use dropout or not. Default: False.\n",
    "\n",
    "    Returns:\n",
    "        Tensor, output tensor.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_planes, out_planes, ngf=64, n_layers=7, alpha=0.2, norm_mode='bn', dropout=False):\n",
    "        super(UnetGenerator, self).__init__()\n",
    "        # construct unet structure\n",
    "        unet_block = UnetSkipConnectionBlock(ngf * 8, ngf * 8, in_planes=None, submodule=None,\n",
    "                                             norm_mode=norm_mode, innermost=True)\n",
    "        for _ in range(n_layers - 5):\n",
    "            unet_block = UnetSkipConnectionBlock(ngf * 8, ngf * 8, in_planes=None, submodule=unet_block,\n",
    "                                                 norm_mode=norm_mode, dropout=dropout)\n",
    "        # gradually reduce the number of filters from ngf * 8 to ngf\n",
    "        unet_block = UnetSkipConnectionBlock(ngf * 4, ngf * 8, in_planes=None, submodule=unet_block,\n",
    "                                             norm_mode=norm_mode)\n",
    "        unet_block = UnetSkipConnectionBlock(ngf * 2, ngf * 4, in_planes=None, submodule=unet_block,\n",
    "                                             norm_mode=norm_mode)\n",
    "        unet_block = UnetSkipConnectionBlock(ngf, ngf * 2, in_planes=None, submodule=unet_block, norm_mode=norm_mode)\n",
    "        self.model = UnetSkipConnectionBlock(out_planes, ngf, in_planes=in_planes, submodule=unet_block,\n",
    "                                             outermost=True, norm_mode=norm_mode)\n",
    "\n",
    "    def construct(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class UnetSkipConnectionBlock(nn.Cell):\n",
    "    \"\"\"Unet submodule with skip connection.\n",
    "\n",
    "    Args:\n",
    "        outer_nc (int): The number of filters in the outer conv layer\n",
    "        inner_nc (int): The number of filters in the inner conv layer\n",
    "        in_planes (int): The number of channels in input images/features\n",
    "        dropout (bool): Use dropout or not. Default: False.\n",
    "        submodule (Cell): Previously defined submodules\n",
    "        outermost (bool): If this module is the outermost module\n",
    "        innermost (bool): If this module is the innermost module\n",
    "        alpha (float): LeakyRelu slope. Default: 0.2.\n",
    "        norm_mode (str): Specifies norm method. The optional values are \"batch\", \"instance\".\n",
    "\n",
    "    Returns:\n",
    "        Tensor, output tensor.\n",
    "    \"\"\"\n",
    "    def __init__(self, outer_nc, inner_nc, in_planes=None, dropout=False,\n",
    "                 submodule=None, outermost=False, innermost=False, alpha=0.2, norm_mode='batch'):\n",
    "        super(UnetSkipConnectionBlock, self).__init__()\n",
    "        downnorm = nn.BatchNorm2d(inner_nc)\n",
    "        upnorm = nn.BatchNorm2d(outer_nc)\n",
    "        use_bias = False\n",
    "        if norm_mode == 'instance':\n",
    "            downnorm = nn.BatchNorm2d(inner_nc, affine=False)\n",
    "            upnorm = nn.BatchNorm2d(outer_nc, affine=False)\n",
    "            use_bias = True\n",
    "        if in_planes is None:\n",
    "            in_planes = outer_nc\n",
    "        downconv = nn.Conv2d(in_planes, inner_nc, kernel_size=4,\n",
    "                             stride=2, padding=1, has_bias=use_bias, pad_mode='pad')\n",
    "        downrelu = nn.LeakyReLU(alpha)\n",
    "        uprelu = nn.ReLU()\n",
    "\n",
    "        if outermost:\n",
    "            upconv = nn.Conv2dTranspose(inner_nc * 2, outer_nc,\n",
    "                                        kernel_size=4, stride=2,\n",
    "                                        padding=1, pad_mode='pad')\n",
    "            down = [downconv]\n",
    "            up = [uprelu, upconv, nn.Tanh()]\n",
    "            model = down + [submodule] + up\n",
    "        elif innermost:\n",
    "            upconv = nn.Conv2dTranspose(inner_nc, outer_nc,\n",
    "                                        kernel_size=4, stride=2,\n",
    "                                        padding=1, has_bias=use_bias, pad_mode='pad')\n",
    "            down = [downrelu, downconv]\n",
    "            up = [uprelu, upconv, upnorm]\n",
    "            model = down + up\n",
    "        else:\n",
    "            upconv = nn.Conv2dTranspose(inner_nc * 2, outer_nc,\n",
    "                                        kernel_size=4, stride=2,\n",
    "                                        padding=1, has_bias=use_bias, pad_mode='pad')\n",
    "            down = [downrelu, downconv, downnorm]\n",
    "            up = [uprelu, upconv, upnorm]\n",
    "\n",
    "            model = down + [submodule] + up\n",
    "            if dropout:\n",
    "                model.append(nn.Dropout(0.5))\n",
    "\n",
    "        self.model = nn.SequentialCell(model)\n",
    "        self.skip_connections = not outermost\n",
    "        self.concat = ops.Concat(axis=1)\n",
    "\n",
    "    def construct(self, x):\n",
    "        out = self.model(x)\n",
    "        if self.skip_connections:\n",
    "            if x.shape[-1] != out.shape[-1]:\n",
    "                out = ops.ResizeBilinear(x.shape)(out)\n",
    "            out = self.concat((out, x))\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实例化生成器\n",
    "\n",
    "通过`model`参数来指定生成器的结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_generator(args):\n",
    "    \"\"\"\n",
    "    This class implements the CycleGAN model, for learning image-to-image translation without paired data.\n",
    "\n",
    "    The model training requires '--dataset_mode unaligned' dataset.\n",
    "    By default, it uses a '--netG resnet_9blocks' ResNet generator,\n",
    "    a '--netD basic' discriminator (PatchGAN introduced by pix2pix),\n",
    "    and a least-square GANs objective ('--gan_mode lsgan').\n",
    "    \"\"\"\n",
    "    if args.model == \"ResNet\":\n",
    "        net = ResNetGenerator(in_planes=args.in_planes, ngf=args.ngf, n_layers=args.gl_num,\n",
    "                              alpha=args.slope, norm_mode=args.norm_mode, dropout=args.need_dropout,\n",
    "                              pad_mode=args.pad_mode)\n",
    "        init_weights(net, args.init_type, args.init_gain)\n",
    "    elif args.model == \"DepthResNet\":\n",
    "        net = DepthResNetGenerator(in_planes=args.in_planes, ngf=args.ngf, n_layers=args.gl_num,\n",
    "                                   alpha=args.slope, norm_mode=args.norm_mode, dropout=args.need_dropout,\n",
    "                                   pad_mode=args.pad_mode)\n",
    "        init_weights(net, args.init_type, args.init_gain)\n",
    "    elif args.model == \"UNet\":\n",
    "        if args.image_size % (2 ** (args.gl_num + 1)) != 0:\n",
    "            raise ValueError(f\"For UNet Generator, the image_size must be a multiple of 2 ** (gl_num + 1), \"\n",
    "                             f\"please adjust the image_size or gl_num, now the image_size is {args.image_size} \"\n",
    "                             f\"gl_num is {args.gl_num}, it is recommended that gl_num = 7.\")\n",
    "        net = UnetGenerator(in_planes=args.in_planes, out_planes=args.in_planes, ngf=args.ngf, n_layers=args.gl_num,\n",
    "                            alpha=args.slope, norm_mode=args.norm_mode, dropout=args.need_dropout)\n",
    "        init_weights(net, args.init_type, args.init_gain)\n",
    "    else:\n",
    "        raise NotImplementedError(f'Model {args.model} not recognized.')\n",
    "    return net\n",
    "\n",
    "# args = get_args(\"train\")\n",
    "args.model = \"ResNet\"\n",
    "\n",
    "net_rg_a = get_generator(args)\n",
    "net_rg_a.update_parameters_name('net_rg_a.')\n",
    "\n",
    "net_rg_b = get_generator(args)\n",
    "net_rg_b.update_parameters_name('net_rg_b.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 构建判别器\n",
    "\n",
    "判别器其实是一个二分类网络模型，输出判定该图像为真实图的概率。网络模型使用的是 Patch 大小为 70x70 的 PatchGANs 模型。通过一系列的 `Conv2d` 、 `BatchNorm2d` 和 `LeakyReLU` 层对其进行处理，最后通过 Sigmoid 激活函数得到最终概率。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Cell):\n",
    "    \"\"\"\n",
    "    Discriminator of GAN.\n",
    "    Args:\n",
    "        in_planes (int): Input channel.\n",
    "        ndf (int): Output channel.\n",
    "        n_layers (int): The number of ConvNormReLU blocks.\n",
    "        alpha (float): LeakyRelu slope. Default: 0.2.\n",
    "        norm_mode (str): Specifies norm method. The optional values are \"batch\", \"instance\".\n",
    "    Returns:\n",
    "        Tensor, output tensor.\n",
    "    Examples:\n",
    "        >>> Discriminator(3, 64, 3)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_planes=3, ndf=64, n_layers=3, alpha=0.2, norm_mode='batch'):\n",
    "        super(Discriminator, self).__init__()\n",
    "        kernel_size = 4\n",
    "        layers = [\n",
    "            nn.Conv2d(in_planes, ndf, kernel_size, 2, pad_mode='pad', padding=1),\n",
    "            nn.LeakyReLU(alpha)\n",
    "        ]\n",
    "        nf_mult = ndf\n",
    "        for i in range(1, n_layers):\n",
    "            nf_mult_prev = nf_mult\n",
    "            nf_mult = min(2 ** i, 8) * ndf\n",
    "            layers.append(ConvNormReLU(nf_mult_prev, nf_mult, kernel_size, 2, alpha, norm_mode, padding=1))\n",
    "        nf_mult_prev = nf_mult\n",
    "        nf_mult = min(2 ** n_layers, 8) * ndf\n",
    "        layers.append(ConvNormReLU(nf_mult_prev, nf_mult, kernel_size, 1, alpha, norm_mode, padding=1))\n",
    "        layers.append(nn.Conv2d(nf_mult, 1, kernel_size, 1, pad_mode='pad', padding=1))\n",
    "        self.features = nn.SequentialCell(layers)\n",
    "\n",
    "    def construct(self, x):\n",
    "        output = self.features(x)\n",
    "        return output\n",
    "\n",
    "\n",
    "def get_discriminator(args):\n",
    "    \"\"\"Return discriminator by args.\"\"\"\n",
    "    net = Discriminator(in_planes=args.in_planes, ndf=args.ndf, n_layers=args.dl_num,\n",
    "                        alpha=args.slope, norm_mode=args.norm_mode)\n",
    "    init_weights(net, args.init_type, args.init_gain)\n",
    "    return net\n",
    "\n",
    "net_d_a = get_discriminator(args)\n",
    "net_d_a.update_parameters_name('net_d_a.')\n",
    "\n",
    "net_d_b = get_discriminator(args)\n",
    "net_d_b.update_parameters_name('net_d_b.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化器和损失函数\n",
    "\n",
    "根据不同模型需要单独的设置优化器，这是训练过程决定的。\n",
    "\n",
    "对生成器 $G$ 及其判别器 $D_{Y}$ ，目标损失函数定义为:\n",
    "\n",
    "$$L_{GAN}(G,D_Y,X,Y)=E_{y-p_{data}(y)}[logD_Y(y)]+E_{x-p_{data}(x)}[log(1-D_Y(G(x)))]$$\n",
    "\n",
    "其中 $G$ 试图生成看起来与 $Y$ 中的图像相似的图像 $G(x)$ ，而 $D_{Y}$ 的目标是区分翻译样本 $G(x)$ 和真实样本 $y$ ，生成器的目标是最小化这个损失函数以此来对抗判别器。即 $ min_{G} max_{D_{Y}}L_{GAN}(G,D_{Y} ,X,Y )$ 。\n",
    "\n",
    "单独的对抗损失不能保证所学函数可以将单个输入映射到期望的输出，为了进一步减少可能的映射函数的空间，学习到的映射函数应该是周期一致的，例如对于 $X$ 的每个图像 $x$ ，图像转换周期应能够将 $x$ 带回原始图像，可以称之为正向循环一致性，即 $x→G(x)→F(G(x))\\approx x$ 。对于 $Y$ ，类似的 $x→G(x)→F(G(x))\\approx x$ 。可以理解采用了一个循环一致性损失来激励这种行为。\n",
    "\n",
    "循环一致损失函数定义如下：\n",
    "\n",
    "$$L_{cyc}(G,F)=E_{x-p_{data}(x)}[\\Vert F(G(x))-x\\Vert_{1}]+E_{y-p_{data}(y)}[\\Vert G(F(y))-y\\Vert_{1}]$$\n",
    "\n",
    "循环一致损失能够保证重建图像 $F(G(x))$ 与输入图像 $x$ 紧密匹配。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"Cycle GAN losses\"\"\"\n",
    "\n",
    "from mindspore import dtype\n",
    "import mindspore.nn as nn\n",
    "import mindspore.ops as ops\n",
    "from mindspore import Tensor\n",
    "\n",
    "\n",
    "class BCEWithLogits(nn.Cell):\n",
    "    \"\"\"\n",
    "    BCEWithLogits creates a criterion to measure the Binary Cross Entropy between the true labels and\n",
    "    predicted labels with sigmoid logits.\n",
    "    Args:\n",
    "        reduction (str): Specifies the reduction to be applied to the output.\n",
    "            Its value must be one of 'none', 'mean', 'sum'. Default: 'none'.\n",
    "    Outputs:\n",
    "        Tensor or Scalar, if `reduction` is 'none', then output is a tensor and has the same shape as `inputs`.\n",
    "        Otherwise, the output is a scalar.\n",
    "    \"\"\"\n",
    "    def __init__(self, reduction='mean'):\n",
    "        super(BCEWithLogits, self).__init__()\n",
    "        if reduction is None:\n",
    "            reduction = 'none'\n",
    "        if reduction not in ('mean', 'sum', 'none'):\n",
    "            raise ValueError(f\"reduction method for {reduction.lower()} is not supported\")\n",
    "\n",
    "        self.loss = ops.SigmoidCrossEntropyWithLogits()\n",
    "        self.reduce = False\n",
    "        if reduction == 'sum':\n",
    "            self.reduce_mode = ops.ReduceSum()\n",
    "            self.reduce = True\n",
    "        elif reduction == 'mean':\n",
    "            self.reduce_mode = ops.ReduceMean()\n",
    "            self.reduce = True\n",
    "    def construct(self, predict, target):\n",
    "        loss = self.loss(predict, target)\n",
    "        if self.reduce:\n",
    "            loss = self.reduce_mode(loss)\n",
    "        return loss\n",
    "\n",
    "def get_lr(args):\n",
    "    \"\"\"\n",
    "    Learning rate generator.\n",
    "    For 'linear', we keep the same learning rate for the first <opt.n_epochs> epochs\n",
    "    and linearly decay the rate to zero over the next <opt.n_epochs_decay> epochs.\n",
    "    \"\"\"\n",
    "    if args.lr_policy == 'linear':\n",
    "        lrs = [args.lr] * args.dataset_size * args.n_epochs\n",
    "        lr_epoch = 0\n",
    "        for epoch in range(args.n_epochs_decay):\n",
    "            lr_epoch = args.lr * (args.n_epochs_decay - epoch) / args.n_epochs_decay\n",
    "            lrs += [lr_epoch] * args.dataset_size\n",
    "        lrs += [lr_epoch] * args.dataset_size * (args.max_epoch - args.n_epochs_decay - args.n_epochs)\n",
    "        return Tensor(np.array(lrs).astype(np.float32))\n",
    "    return args.lr\n",
    "\n",
    "# 构建生成器，判别器优化器\n",
    "optimizer_rg_a = nn.Adam(net_rg_a.trainable_params(), get_lr(args), beta1=args.beta1)\n",
    "optimizer_rg_b = nn.Adam(net_rg_b.trainable_params(), get_lr(args), beta1=args.beta1)\n",
    "\n",
    "optimizer_d_a = nn.Adam(net_d_a.trainable_params(), get_lr(args), beta1=args.beta1)\n",
    "optimizer_d_b = nn.Adam(net_d_b.trainable_params(), get_lr(args), beta1=args.beta1)\n",
    "\n",
    "# GAN网络损失函数\n",
    "def get_loss_fn(args, reduction='mean'):\n",
    "    loss_fn = None\n",
    "    if args.gan_mode == \"lsgan\":\n",
    "        loss_fn = nn.MSELoss(reduction)\n",
    "    elif args.gan_mode == \"vanilla\":\n",
    "        loss_fn = BCEWithLogits(reduction)\n",
    "    else:\n",
    "        raise NotImplementedError(f'GANLoss {mode} not recognized, we support lsgan and vanilla.') \n",
    "    return loss_fn\n",
    "\n",
    "loss_fn = get_loss_fn(args)\n",
    "l1_loss = nn.L1Loss(\"mean\")\n",
    "\n",
    "def gan_loss(predict, target):\n",
    "    target = ops.cast(target, ops.dtype(predict))\n",
    "    target = ops.ones_like(predict) * target\n",
    "    loss = loss_fn(predict, target)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前向计算\n",
    "\n",
    "搭建模型前向计算损失的过程，过程如下代码。\n",
    "\n",
    "为了减少模型振荡[1]，这里遵循 Shrivastava 等人的策略[2]，使用生成器生成图像的历史数据而不是生成器生成的最新图像数据来更新鉴别器。这里创建 `ImagePool` 类，保留了一个图像缓冲区，用于存储生成器生成前的50个图像。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generator(img_a, img_b, use_identity=True):\n",
    "    fake_a = net_rg_b(img_b)\n",
    "    fake_b = net_rg_a(img_a)\n",
    "    rec_a = net_rg_b(fake_b)\n",
    "    rec_b = net_rg_a(fake_a)\n",
    "    if use_identity:\n",
    "        identity_a = net_rg_b(img_a)\n",
    "        identity_b = net_rg_a(img_b)\n",
    "    else:\n",
    "        identity_a = ops.ones_like(img_a)\n",
    "        identity_b = ops.ones_like(img_b)\n",
    "    return fake_a, fake_b, rec_a, rec_b, identity_a, identity_b\n",
    "\n",
    "args.lambda_A = 10.0\n",
    "args.lambda_B = 10.0\n",
    "args.lambda_idt = 0.5\n",
    "\n",
    "def generator_forward(img_a, img_b):\n",
    "    true = Tensor(True, dtype.bool_)\n",
    "    fake_a, fake_b, rec_a, rec_b, identity_a, identity_b = generator(img_a, img_b, args.lambda_idt > 0)\n",
    "    loss_g_a = gan_loss(net_d_b(fake_b), true)\n",
    "    loss_g_b = gan_loss(net_d_a(fake_a), true)\n",
    "    loss_c_a = l1_loss(rec_a, img_a) * args.lambda_A\n",
    "    loss_c_b = l1_loss(rec_b, img_b) * args.lambda_B\n",
    "    if args.lambda_idt > 0:\n",
    "        loss_idt_a = l1_loss(identity_a, img_a) * args.lambda_A * args.lambda_idt\n",
    "        loss_idt_b = l1_loss(identity_b, img_b) * args.lambda_B * args.lambda_idt\n",
    "    else:\n",
    "        loss_idt_a = 0\n",
    "        loss_idt_b = 0\n",
    "    loss_g = loss_g_a + loss_g_b + loss_c_a + loss_c_b + loss_idt_a + loss_idt_b\n",
    "    return fake_a, fake_b, loss_g, loss_g_a, loss_g_b, loss_c_a, loss_c_b, loss_idt_a, loss_idt_b\n",
    "\n",
    "def generator_forward_grad(img_a, img_b):\n",
    "    _, _, loss_g, _, _, _, _, _, _ = generator_forward(img_a, img_b)\n",
    "    return loss_g\n",
    "\n",
    "def discriminator_forward(img_a, img_b, fake_a, fake_b):\n",
    "    false = Tensor(False, dtype.bool_)\n",
    "    true = Tensor(True, dtype.bool_)\n",
    "    d_fake_a = net_d_a(fake_a)\n",
    "    d_img_a = net_d_a(img_a)\n",
    "    d_fake_b = net_d_b(fake_b)\n",
    "    d_img_b = net_d_b(img_b)\n",
    "    loss_d_a = gan_loss(d_fake_a, false) + gan_loss(d_img_a, true)\n",
    "    loss_d_b = gan_loss(d_fake_b, false) + gan_loss(d_img_b, true)\n",
    "    loss_d = (loss_d_a + loss_d_b) * 0.5\n",
    "    return loss_d\n",
    "\n",
    "def discriminator_forward_a(img_a, fake_a):\n",
    "    false = Tensor(False, dtype.bool_)\n",
    "    true = Tensor(True, dtype.bool_)\n",
    "    d_fake_a = net_d_a(fake_a)\n",
    "    d_img_a = net_d_a(img_a)\n",
    "    loss_d_a = gan_loss(d_fake_a, false) + gan_loss(d_img_a, true)\n",
    "    return loss_d_a\n",
    "\n",
    "def discriminator_forward_b(img_b, fake_b):\n",
    "    false = Tensor(False, dtype.bool_)\n",
    "    true = Tensor(True, dtype.bool_)\n",
    "    d_fake_b = net_d_b(fake_b)\n",
    "    d_img_b = net_d_b(img_b)\n",
    "    loss_d_b = gan_loss(d_fake_b, false) + gan_loss(d_img_b, true)\n",
    "    return loss_d_b\n",
    "\n",
    "\n",
    "class ImagePool():\n",
    "    \"\"\"\n",
    "    This class implements an image buffer that stores previously generated images.\n",
    "    This buffer enables us to update discriminators using a history of generated images\n",
    "    rather than the ones produced by the latest generators.\n",
    "    \"\"\"\n",
    "    def __init__(self, pool_size):\n",
    "        \"\"\"\n",
    "        Initialize the ImagePool class\n",
    "        Args:\n",
    "            pool_size (int): the size of image buffer, if pool_size=0, no buffer will be created.\n",
    "        \"\"\"\n",
    "        self.pool_size = pool_size\n",
    "        if self.pool_size > 0:  # create an empty pool\n",
    "            self.num_imgs = 0\n",
    "            self.images = []\n",
    "\n",
    "    def query(self, images):\n",
    "        \"\"\"\n",
    "        Return an image from the pool.\n",
    "        Args:\n",
    "            images: the latest generated images from the generator\n",
    "        Returns images Tensor from the buffer.\n",
    "        By 50/100, the buffer will return input images.\n",
    "        By 50/100, the buffer will return images previously stored in the buffer,\n",
    "        and insert the current images to the buffer.\n",
    "        \"\"\"\n",
    "        if isinstance(images, Tensor):\n",
    "            images = images.asnumpy()\n",
    "        if self.pool_size == 0:  # if the buffer size is 0, do nothing\n",
    "            return Tensor(images)\n",
    "        return_images = []\n",
    "        for image in images:\n",
    "            if self.num_imgs < self.pool_size:   # if the buffer is not full; keep inserting current images to the buffer\n",
    "                self.num_imgs = self.num_imgs + 1\n",
    "                self.images.append(image)\n",
    "                return_images.append(image)\n",
    "            else:\n",
    "                p = random.uniform(0, 1)\n",
    "                if p > 0.5:  # by 50% chance, the buffer will return a previously stored image, and insert the current image into the buffer\n",
    "                    random_id = random.randint(0, self.pool_size - 1)  # randint is inclusive\n",
    "                    tmp = self.images[random_id].copy()\n",
    "                    self.images[random_id] = image\n",
    "                    return_images.append(tmp)\n",
    "                else:       # by another 50% chance, the buffer will return the current image\n",
    "                    return_images.append(image)\n",
    "        return_images = np.array(return_images)   # collect all the images and return\n",
    "        if len(return_images.shape) != 4:\n",
    "            raise ValueError(\"img should be 4d, but get shape {}\".format(return_images.shape))\n",
    "        return Tensor(return_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算梯度和反向传播\n",
    "\n",
    "其中梯度计算也是分开不同的模型来进行的，详情见如下代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mindspore import value_and_grad\n",
    "\n",
    "# 实例化求梯度的方法\n",
    "grad_g_a = value_and_grad(generator_forward_grad, None, net_rg_a.trainable_params())\n",
    "grad_g_b = value_and_grad(generator_forward_grad, None, net_rg_b.trainable_params())\n",
    "\n",
    "grad_d_a = value_and_grad(discriminator_forward_a, None, net_d_a.trainable_params())\n",
    "grad_d_b = value_and_grad(discriminator_forward_b, None, net_d_b.trainable_params())\n",
    "\n",
    "# 计算生成器的梯度，反向传播更新参数\n",
    "def train_step_g(img_a, img_b):\n",
    "    net_d_a.set_grad(False)\n",
    "    net_d_b.set_grad(False)\n",
    "    \n",
    "    fake_a, fake_b, lg, lga, lgb, lca, lcb, lia, lib = generator_forward(img_a, img_b)\n",
    "    \n",
    "    _, grads_g_a = grad_g_a(img_a, img_b)\n",
    "    _, grads_g_b = grad_g_b(img_a, img_b)\n",
    "    optimizer_rg_a(grads_g_a)\n",
    "    optimizer_rg_b(grads_g_b)\n",
    "\n",
    "    return fake_a, fake_b, lg, lga, lgb, lca, lcb, lia, lib\n",
    "\n",
    "# 计算判别器的梯度，反向传播更新参数\n",
    "def train_step_d(img_a, img_b, fake_a, fake_b):\n",
    "    net_d_a.set_grad(True)\n",
    "    net_d_b.set_grad(True)\n",
    "\n",
    "    loss_d_a, grads_d_a = grad_d_a(img_a, fake_a)\n",
    "    loss_d_b, grads_d_b = grad_d_b(img_b, fake_b)\n",
    "\n",
    "    loss_d = (loss_d_a + loss_d_b) * 0.5\n",
    "\n",
    "    optimizer_d_a(grads_d_a)\n",
    "    optimizer_d_b(grads_d_b)\n",
    "\n",
    "    return loss_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练\n",
    "\n",
    "训练分为两个主要部分：训练判别器和训练生成器，在前文的判别器损失函数中，论文采用了最小二乘损失代替负对数似然目标。\n",
    "\n",
    "- 训练判别器：训练判别器的目的是最大程度地提高判别图像真伪的概率。按照论文的方法需要训练判别器来最小化 $E_{y-p_{data}(y)}[(D(y)-1)^2]$ ；\n",
    "\n",
    "- 训练生成器：如 CycleGAN 论文所述，我们希望通过最小化 $E_{x-p_{data}(x)}[(D(G(x)-1)^2]$ 来训练生成器，以产生更好的虚假图像。\n",
    "\n",
    "下面定义了生成器和判别器的训练过程：\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义训练过程中用到的工具\n",
    "\n",
    "创建图片保存、获取学习率、加载权重的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mindspore import load_checkpoint, load_param_into_net\n",
    "\n",
    "\n",
    "def save_image(img, img_path, random_id=0):\n",
    "    \"\"\"Save a numpy image to the disk\n",
    "    Parameters:\n",
    "        img (numpy array / Tensor): image to save.\n",
    "        image_path (str): the path of the image.\n",
    "        random_id (int): the number range in 0 ~ batch_size to be saved.\n",
    "    \"\"\"\n",
    "    if isinstance(img, Tensor):\n",
    "        img = img.asnumpy()\n",
    "    elif not isinstance(img, np.ndarray):\n",
    "        raise ValueError(\"img should be Tensor or numpy array, but get {}\".format(type(img)))\n",
    "    img = decode_image(img, random_id)\n",
    "    img_pil = Image.fromarray(img)\n",
    "    img_pil.save(img_path)\n",
    "\n",
    "\n",
    "def decode_image(img, random_id=0):\n",
    "    \"\"\"Decode a [1, C, H, W] Tensor to image numpy array.\"\"\"\n",
    "    mean = 0.5 * 255\n",
    "    std = 0.5 * 255\n",
    "    \n",
    "    return (img[random_id] * std + mean).astype(np.uint8).transpose((1, 2, 0))\n",
    "\n",
    "\n",
    "def load_ckpt(args, G_A, G_B, D_A=None, D_B=None):\n",
    "    \"\"\"Load parameter from checkpoint.\"\"\"\n",
    "    if args.G_A_ckpt is not None:\n",
    "        param_GA = load_checkpoint(args.G_A_ckpt)\n",
    "        load_param_into_net(G_A, param_GA)\n",
    "    if args.G_B_ckpt is not None:\n",
    "        param_GB = load_checkpoint(args.G_B_ckpt)\n",
    "        load_param_into_net(G_B, param_GB)\n",
    "    if D_A is not None and args.D_A_ckpt is not None:\n",
    "        param_DA = load_checkpoint(args.D_A_ckpt)\n",
    "        load_param_into_net(D_A, param_DA)\n",
    "    if D_B is not None and args.D_B_ckpt is not None:\n",
    "        param_DB = load_checkpoint(args.D_B_ckpt)\n",
    "        load_param_into_net(D_B, param_DB)\n",
    "\n",
    "\n",
    "def enable_batch_statistics(net):\n",
    "    \"\"\"Enable batch statistics in all BatchNorms\"\"\"\n",
    "    if isinstance(net, nn.BatchNorm2d):\n",
    "        net.use_batch_statistics = True\n",
    "    else:\n",
    "        for cell in net.cells():\n",
    "            enable_batch_statistics(cell)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义Reporter类\n",
    "\n",
    "监听训练过程中的数据，打印日志"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"Reporter class.\"\"\"\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import random\n",
    "from mindspore import save_checkpoint\n",
    "\n",
    "\n",
    "class Reporter(logging.Logger):\n",
    "    \"\"\"\n",
    "    This class includes several functions that can save images/checkpoints and print/save logging information.\n",
    "    Args:\n",
    "        args (class): Option class.\n",
    "    \"\"\"\n",
    "    def __init__(self, args):\n",
    "        super(Reporter, self).__init__(\"cyclegan\")\n",
    "        self.log_dir = os.path.join(args.outputs_dir, 'log')\n",
    "        self.ckpts_dir = os.path.join(args.outputs_dir, \"ckpt\")\n",
    "        self.imgs_dir = os.path.join(args.outputs_dir, \"imgs\")\n",
    "        if not os.path.exists(self.log_dir):\n",
    "            os.makedirs(self.log_dir, exist_ok=True)\n",
    "        if not os.path.exists(self.ckpts_dir):\n",
    "            os.makedirs(self.ckpts_dir, exist_ok=True)\n",
    "        if not os.path.exists(self.imgs_dir):\n",
    "            os.makedirs(self.imgs_dir, exist_ok=True)\n",
    "        self.rank = args.rank\n",
    "        self.save_checkpoint_epochs = args.save_checkpoint_epochs\n",
    "        self.save_imgs = args.save_imgs\n",
    "        # console handler\n",
    "        console = logging.StreamHandler()\n",
    "        console.setLevel(logging.INFO)\n",
    "        formatter = logging.Formatter('%(message)s')\n",
    "        console.setFormatter(formatter)\n",
    "        self.addHandler(console)\n",
    "        # file handler\n",
    "        log_name = datetime.now().strftime('%Y-%m-%d_time_%H_%M_%S') + '_rank_{}.log'.format(self.rank)\n",
    "        self.log_fn = os.path.join(self.log_dir, log_name)\n",
    "        fh = logging.FileHandler(self.log_fn)\n",
    "        fh.setLevel(logging.INFO)\n",
    "        fh.setFormatter(formatter)\n",
    "        self.addHandler(fh)\n",
    "        self.save_args(args)\n",
    "        self.step = 0\n",
    "        self.epoch = 0\n",
    "        self.batch_size = args.batch_size\n",
    "        self.n_steps = args.dataset_size // args.batch_size\n",
    "        print(args.dataset_size, self.n_steps)\n",
    "        self.dataset_size = args.dataset_size // args.device_num\n",
    "        self.save_img_nums = args.save_img_nums\n",
    "        self.device_num = args.device_num\n",
    "        self.print_iter = args.print_iter\n",
    "        self.G_loss = []\n",
    "        self.D_loss = []\n",
    "\n",
    "    def info(self, msg, *args, **kwargs):\n",
    "        if self.isEnabledFor(logging.INFO):\n",
    "            self._log(logging.INFO, msg, args, **kwargs)\n",
    "\n",
    "    def save_args(self, args):\n",
    "        self.info('Args:')\n",
    "        args_dict = vars(args)\n",
    "        for key in args_dict.keys():\n",
    "            self.info('--> %s: %s', key, args_dict[key])\n",
    "        self.info('')\n",
    "\n",
    "    def epoch_start(self):\n",
    "        self.step_start_time = time.time()\n",
    "        self.epoch_start_time = time.time()\n",
    "        self.step = 0\n",
    "        self.epoch += 1\n",
    "        self.G_loss = []\n",
    "        self.D_loss = []\n",
    "\n",
    "        random.seed()\n",
    "        self.random_imgs_out_steps = random.sample(range(1, self.n_steps+1), self.save_img_nums)\n",
    "        \n",
    "        self.imgs_epoch_dir = os.path.join(self.imgs_dir, str(self.epoch))\n",
    "        if not os.path.exists(self.imgs_epoch_dir):\n",
    "            os.makedirs(self.imgs_epoch_dir, exist_ok=True)\n",
    "\n",
    "    def step_end(self, res_G, res_D):\n",
    "        \"\"\"print log when step end.\"\"\"\n",
    "        self.step += 1\n",
    "        loss_D = float(res_D.asnumpy())\n",
    "        res = []\n",
    "        for item in res_G[2:]:\n",
    "            res.append(float(item.asnumpy()))\n",
    "        self.G_loss.append(res[0])\n",
    "        self.D_loss.append(loss_D)\n",
    "        if self.step % self.print_iter == 0:\n",
    "            step_cost = (time.time() - self.step_start_time) * 1000 / self.print_iter\n",
    "            losses = \"G_loss: {:.2f}, D_loss:{:.2f}, loss_G_A: {:.2f}, loss_G_B: {:.2f}, loss_C_A: {:.2f},\"\\\n",
    "                     \"loss_C_B: {:.2f}, loss_idt_A: {:.2f}, loss_idt_B：{:.2f}\".format(\n",
    "                         res[0], loss_D, res[1], res[2], res[3], res[4], res[5], res[6])\n",
    "            self.info(\"Epoch[{}] [{}/{}] step cost: {:.2f} ms, {}\".format(\n",
    "                self.epoch, self.step, self.dataset_size, step_cost, losses))\n",
    "            self.step_start_time = time.time()\n",
    "\n",
    "    def epoch_end(self):\n",
    "        \"\"\"print log and save checkpoints when epoch end.\"\"\"\n",
    "        epoch_cost = (time.time() - self.epoch_start_time) * 1000\n",
    "        per_step_time = epoch_cost / self.dataset_size\n",
    "        mean_loss_G = sum(self.G_loss) / self.dataset_size\n",
    "        mean_loss_D = sum(self.D_loss) / self.dataset_size\n",
    "        self.info(\"Epoch [{}] total cost: {:.2f} ms, per step: {:.2f} ms, G_loss: {:.2f}, D_loss: {:.2f}\".format(\n",
    "            self.epoch, epoch_cost, per_step_time, mean_loss_G, mean_loss_D))\n",
    "\n",
    "        if self.epoch % self.save_checkpoint_epochs == 0:\n",
    "            save_checkpoint(net_rg_a, os.path.join(self.ckpts_dir, f\"G_A_{self.epoch}.ckpt\"))\n",
    "            save_checkpoint(net_rg_b, os.path.join(self.ckpts_dir, f\"G_B_{self.epoch}.ckpt\"))\n",
    "            save_checkpoint(net_d_a, os.path.join(self.ckpts_dir, f\"D_A_{self.epoch}.ckpt\"))\n",
    "            save_checkpoint(net_d_b, os.path.join(self.ckpts_dir, f\"D_B_{self.epoch}.ckpt\"))\n",
    "            # left latest 20, remove outdated ckpts.\n",
    "            ckpt_files = [os.path.join(self.ckpts_dir, file) for file in os.listdir(self.ckpts_dir)]\n",
    "            ckpt_files = sorted(ckpt_files, key=os.path.getmtime)\n",
    "            if len(ckpt_files) > 20:\n",
    "                for i in range(len(ckpt_files) - 20):\n",
    "                    os.remove(ckpt_files[i])\n",
    "\n",
    "    def visualizer(self, img_A, img_B, fake_A, fake_B):\n",
    "        # print(self.step, self.random_imgs_out_steps, len(self.random_imgs_out_steps))\n",
    "        if self.save_imgs and self.step in self.random_imgs_out_steps:\n",
    "            random.seed()\n",
    "            random_id = random.randint(0, self.batch_size-1)\n",
    "            save_image(img_A, os.path.join(self.imgs_epoch_dir, f\"{self.epoch}_{self.step}_{random_id}_img_B.png\"), random_id)\n",
    "            save_image(fake_B, os.path.join(self.imgs_epoch_dir, f\"{self.epoch}_{self.step}_{random_id}_fake_B.png\"), random_id)\n",
    "\n",
    "    def start_predict(self, direction):\n",
    "        self.predict_start_time = time.time()\n",
    "        self.direction = direction\n",
    "        self.info('==========start predict %s===============', self.direction)\n",
    "\n",
    "    def end_predict(self):\n",
    "        cost = (time.time() - self.predict_start_time) * 1000\n",
    "        per_step_cost = cost / self.dataset_size\n",
    "        self.info('total {} imgs cost {:.2f} ms, per img cost {:.2f}'.format(self.dataset_size, cost, per_step_cost))\n",
    "        self.info('==========end predict %s===============\\n', self.direction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练\n",
    "\n",
    "开始训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Args:\n",
      "--> platform: Ascend\n",
      "--> device_id: 0\n",
      "--> device_num: 1\n",
      "--> is_save_on_master: 1\n",
      "--> rank: 0\n",
      "--> group_size: 1\n",
      "--> model: ResNet\n",
      "--> init_type: normal\n",
      "--> init_gain: 0.02\n",
      "--> image_size: 256\n",
      "--> batch_size: 1\n",
      "--> pool_size: 50\n",
      "--> beta1: 0.5\n",
      "--> lr: 0.0002\n",
      "--> lr_policy: linear\n",
      "--> max_epoch: 10\n",
      "--> n_epochs: 100\n",
      "--> in_planes: 3\n",
      "--> ngf: 64\n",
      "--> gl_num: 9\n",
      "--> ndf: 64\n",
      "--> dl_num: 3\n",
      "--> slope: 0.2\n",
      "--> norm_mode: instance\n",
      "--> lambda_A: 10.0\n",
      "--> lambda_B: 10.0\n",
      "--> lambda_idt: 0.5\n",
      "--> gan_mode: lsgan\n",
      "--> pad_mode: CONSTANT\n",
      "--> dataroot: ./data/dataset/\n",
      "--> data_dir: testA\n",
      "--> outputs_dir: ./outputs\n",
      "--> load_ckpt: False\n",
      "--> G_A_ckpt: ./outputs/ckpt/G_A_200.ckpt\n",
      "--> G_B_ckpt: ./outputs/ckpt/G_B_200.ckpt\n",
      "--> D_A_ckpt: ./outputs/ckpt/D_A_200.ckpt\n",
      "--> D_B_ckpt: ./outputs/ckpt/D_B_200.ckpt\n",
      "--> save_checkpoint_epochs: 10\n",
      "--> print_iter: 100\n",
      "--> need_profiler: False\n",
      "--> save_graphs: False\n",
      "--> save_imgs: True\n",
      "--> save_img_nums: 10\n",
      "--> use_random: True\n",
      "--> need_dropout: False\n",
      "--> max_dataset_size: inf\n",
      "--> export_batch_size: 1\n",
      "--> export_file_name: CycleGAN\n",
      "--> export_file_format: MINDIR\n",
      "--> n_epochs_decay: 100\n",
      "--> phase: train\n",
      "--> dataset_size: 300\n",
      "\n",
      "==========start training===============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:30:46.863.534 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/3499774006.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:30:46.863.628 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/3499774006.py]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:15.456.235 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/3499774006.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:15.456.313 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/3499774006.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:17.430.261 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2447881219.py]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:23.249.120 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2447881219.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:31.925.925 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:31.926.000 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:31.926.050 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:31.927.060 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:31.927.095 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:31.927.123 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:31.927.150 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:31.927.175 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:31.927.200 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:31.927.228 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:31.927.256 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:31.927.284 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:31.927.312 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:31.927.337 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:31.927.362 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:31.927.387 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:31.927.411 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:31.927.436 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:32.132.924 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:32.132.965 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:32.132.995 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:32.133.016 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:32.133.036 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:32.133.060 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:32.133.082 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:32.133.101 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:32.133.121 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.280.628 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.280.704 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.280.748 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.281.747 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.281.782 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.281.810 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.281.835 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.281.860 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.281.886 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.281.912 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.281.939 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.281.966 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.281.994 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.282.018 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.282.044 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.282.069 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.282.094 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.282.119 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.484.722 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.484.767 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.484.791 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.484.812 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.484.833 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.485.053 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.485.079 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.485.100 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.485.121 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:33:05.717.102 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:33:05.717.179 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:33:05.717.214 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:33:13.137.725 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:33:13.137.798 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:33:13.137.830 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[1] [100/300] step cost: 1704.00 ms, G_loss: 8.69, D_loss:0.26, loss_G_A: 0.50, loss_G_B: 0.72, loss_C_A: 2.70,loss_C_B: 2.28, loss_idt_A: 1.35, loss_idt_B：1.14\n",
      "Epoch[1] [200/300] step cost: 152.48 ms, G_loss: 10.19, D_loss:0.20, loss_G_A: 0.64, loss_G_B: 0.67, loss_C_A: 2.87,loss_C_B: 3.05, loss_idt_A: 1.43, loss_idt_B：1.53\n",
      "Epoch[1] [300/300] step cost: 152.81 ms, G_loss: 12.78, D_loss:0.17, loss_G_A: 0.70, loss_G_B: 0.61, loss_C_A: 2.37,loss_C_B: 5.27, loss_idt_A: 1.19, loss_idt_B：2.64\n",
      "Epoch [1] total cost: 200939.42 ms, per step: 669.80 ms, G_loss: 9.94, D_loss: 0.25\n",
      "Epoch[2] [100/300] step cost: 152.12 ms, G_loss: 9.63, D_loss:0.22, loss_G_A: 0.72, loss_G_B: 0.31, loss_C_A: 3.24,loss_C_B: 2.49, loss_idt_A: 1.62, loss_idt_B：1.24\n",
      "Epoch[2] [200/300] step cost: 151.99 ms, G_loss: 7.01, D_loss:0.26, loss_G_A: 0.60, loss_G_B: 0.75, loss_C_A: 1.74,loss_C_B: 2.03, loss_idt_A: 0.87, loss_idt_B：1.02\n",
      "Epoch[2] [300/300] step cost: 153.33 ms, G_loss: 9.14, D_loss:0.16, loss_G_A: 0.67, loss_G_B: 0.73, loss_C_A: 3.21,loss_C_B: 1.94, loss_idt_A: 1.61, loss_idt_B：0.97\n",
      "Epoch [2] total cost: 45754.82 ms, per step: 152.52 ms, G_loss: 9.99, D_loss: 0.18\n",
      "Epoch[3] [100/300] step cost: 154.41 ms, G_loss: 10.69, D_loss:0.16, loss_G_A: 0.77, loss_G_B: 0.73, loss_C_A: 2.80,loss_C_B: 3.33, loss_idt_A: 1.40, loss_idt_B：1.66\n",
      "Epoch[3] [200/300] step cost: 151.15 ms, G_loss: 11.26, D_loss:0.21, loss_G_A: 0.71, loss_G_B: 0.81, loss_C_A: 1.74,loss_C_B: 4.76, loss_idt_A: 0.87, loss_idt_B：2.38\n",
      "Epoch[3] [300/300] step cost: 150.21 ms, G_loss: 10.93, D_loss:0.13, loss_G_A: 0.77, loss_G_B: 0.78, loss_C_A: 2.80,loss_C_B: 3.45, loss_idt_A: 1.40, loss_idt_B：1.72\n",
      "Epoch [3] total cost: 45587.45 ms, per step: 151.96 ms, G_loss: 10.05, D_loss: 0.16\n",
      "Epoch[4] [100/300] step cost: 151.33 ms, G_loss: 7.20, D_loss:0.30, loss_G_A: 0.72, loss_G_B: 0.76, loss_C_A: 1.11,loss_C_B: 2.71, loss_idt_A: 0.55, loss_idt_B：1.36\n",
      "Epoch[4] [200/300] step cost: 149.62 ms, G_loss: 9.96, D_loss:0.16, loss_G_A: 0.65, loss_G_B: 0.79, loss_C_A: 3.06,loss_C_B: 2.63, loss_idt_A: 1.53, loss_idt_B：1.31\n",
      "Epoch[4] [300/300] step cost: 150.60 ms, G_loss: 9.80, D_loss:0.14, loss_G_A: 0.68, loss_G_B: 0.72, loss_C_A: 2.62,loss_C_B: 2.98, loss_idt_A: 1.31, loss_idt_B：1.49\n",
      "Epoch [4] total cost: 45163.27 ms, per step: 150.54 ms, G_loss: 10.06, D_loss: 0.16\n",
      "Epoch[5] [100/300] step cost: 150.98 ms, G_loss: 10.05, D_loss:0.13, loss_G_A: 0.72, loss_G_B: 0.73, loss_C_A: 3.08,loss_C_B: 2.65, loss_idt_A: 1.54, loss_idt_B：1.32\n",
      "Epoch[5] [200/300] step cost: 149.86 ms, G_loss: 6.54, D_loss:0.22, loss_G_A: 0.73, loss_G_B: 0.74, loss_C_A: 2.44,loss_C_B: 0.93, loss_idt_A: 1.22, loss_idt_B：0.47\n",
      "Epoch[5] [300/300] step cost: 150.63 ms, G_loss: 8.95, D_loss:0.24, loss_G_A: 0.65, loss_G_B: 0.76, loss_C_A: 1.10,loss_C_B: 3.93, loss_idt_A: 0.55, loss_idt_B：1.97\n",
      "Epoch [5] total cost: 45153.93 ms, per step: 150.51 ms, G_loss: 10.07, D_loss: 0.16\n",
      "Epoch[6] [100/300] step cost: 150.24 ms, G_loss: 8.93, D_loss:0.19, loss_G_A: 0.66, loss_G_B: 0.79, loss_C_A: 2.66,loss_C_B: 2.33, loss_idt_A: 1.33, loss_idt_B：1.16\n",
      "Epoch[6] [200/300] step cost: 149.69 ms, G_loss: 10.59, D_loss:0.14, loss_G_A: 0.72, loss_G_B: 0.59, loss_C_A: 2.78,loss_C_B: 3.41, loss_idt_A: 1.39, loss_idt_B：1.70\n",
      "Epoch[6] [300/300] step cost: 150.31 ms, G_loss: 10.09, D_loss:0.13, loss_G_A: 0.65, loss_G_B: 0.81, loss_C_A: 3.22,loss_C_B: 2.54, loss_idt_A: 1.61, loss_idt_B：1.27\n",
      "Epoch [6] total cost: 45031.14 ms, per step: 150.10 ms, G_loss: 10.06, D_loss: 0.16\n",
      "Epoch[7] [100/300] step cost: 150.65 ms, G_loss: 9.93, D_loss:0.15, loss_G_A: 0.54, loss_G_B: 0.71, loss_C_A: 2.60,loss_C_B: 3.18, loss_idt_A: 1.30, loss_idt_B：1.59\n",
      "Epoch[7] [200/300] step cost: 149.81 ms, G_loss: 12.00, D_loss:0.13, loss_G_A: 0.79, loss_G_B: 0.74, loss_C_A: 3.04,loss_C_B: 3.94, loss_idt_A: 1.52, loss_idt_B：1.97\n",
      "Epoch[7] [300/300] step cost: 149.60 ms, G_loss: 8.14, D_loss:0.19, loss_G_A: 0.71, loss_G_B: 0.78, loss_C_A: 2.89,loss_C_B: 1.54, loss_idt_A: 1.45, loss_idt_B：0.77\n",
      "Epoch [7] total cost: 45013.57 ms, per step: 150.05 ms, G_loss: 10.03, D_loss: 0.16\n",
      "Epoch[8] [100/300] step cost: 150.94 ms, G_loss: 10.17, D_loss:0.13, loss_G_A: 0.66, loss_G_B: 0.73, loss_C_A: 2.69,loss_C_B: 3.16, loss_idt_A: 1.34, loss_idt_B：1.58\n",
      "Epoch[8] [200/300] step cost: 151.02 ms, G_loss: 10.23, D_loss:0.13, loss_G_A: 0.71, loss_G_B: 0.82, loss_C_A: 3.28,loss_C_B: 2.52, loss_idt_A: 1.64, loss_idt_B：1.26\n",
      "Epoch[8] [300/300] step cost: 151.10 ms, G_loss: 10.13, D_loss:0.14, loss_G_A: 0.78, loss_G_B: 0.75, loss_C_A: 3.24,loss_C_B: 2.50, loss_idt_A: 1.62, loss_idt_B：1.25\n",
      "Epoch [8] total cost: 45313.86 ms, per step: 151.05 ms, G_loss: 10.05, D_loss: 0.15\n",
      "Epoch[9] [100/300] step cost: 150.24 ms, G_loss: 13.96, D_loss:0.12, loss_G_A: 0.80, loss_G_B: 0.67, loss_C_A: 3.05,loss_C_B: 5.27, loss_idt_A: 1.52, loss_idt_B：2.64\n",
      "Epoch[9] [200/300] step cost: 148.98 ms, G_loss: 9.69, D_loss:0.38, loss_G_A: 0.72, loss_G_B: 0.53, loss_C_A: 2.86,loss_C_B: 2.77, loss_idt_A: 1.43, loss_idt_B：1.38\n",
      "Epoch[9] [300/300] step cost: 149.08 ms, G_loss: 10.80, D_loss:0.22, loss_G_A: 0.66, loss_G_B: 0.51, loss_C_A: 2.75,loss_C_B: 3.67, loss_idt_A: 1.37, loss_idt_B：1.84\n",
      "Epoch [9] total cost: 44836.49 ms, per step: 149.45 ms, G_loss: 69.63, D_loss: 48.57\n",
      "Epoch[10] [100/300] step cost: 149.74 ms, G_loss: 11.77, D_loss:1.06, loss_G_A: 1.19, loss_G_B: 0.55, loss_C_A: 3.30,loss_C_B: 3.38, loss_idt_A: 1.65, loss_idt_B：1.69\n",
      "Epoch[10] [200/300] step cost: 150.44 ms, G_loss: 9.82, D_loss:0.29, loss_G_A: 0.51, loss_G_B: 0.52, loss_C_A: 3.26,loss_C_B: 2.60, loss_idt_A: 1.63, loss_idt_B：1.30\n",
      "Epoch[10] [300/300] step cost: 151.24 ms, G_loss: 12.15, D_loss:0.26, loss_G_A: 0.61, loss_G_B: 0.55, loss_C_A: 3.39,loss_C_B: 3.94, loss_idt_A: 1.69, loss_idt_B：1.97\n",
      "Epoch [10] total cost: 45152.19 ms, per step: 150.51 ms, G_loss: 45.78, D_loss: 33.96\n",
      "==========end training===============\n"
     ]
    }
   ],
   "source": [
    "import mindspore as ms\n",
    "import mindspore.nn as nn\n",
    "\n",
    "ms.set_seed(1)\n",
    "\n",
    "def train():\n",
    "    \"\"\"Train function.\"\"\"\n",
    "    args = get_args(\"train\")\n",
    "    args.model ='ResNet' # 'DepthResNet', 'ResNet', 'UNet' \n",
    "    args.platform = 'Ascend'\n",
    "    args.max_epoch = 100\n",
    "    args.save_img_nums = 10\n",
    "    args.outputs_dir = './outputs'\n",
    "\n",
    "    if args.load_ckpt:\n",
    "        load_ckpt(args, net_rg_a, net_rg_b, net_d_a, net_d_b)\n",
    "    \n",
    "    image_pool_A = ImagePool(args.pool_size)\n",
    "    image_pool_B = ImagePool(args.pool_size)\n",
    "\n",
    "    data_loader = ds.create_dict_iterator()\n",
    "    if args.rank == 0:\n",
    "        reporter = Reporter(args)\n",
    "        reporter.info('==========start training===============')\n",
    "    \n",
    "    for _ in range(args.max_epoch):\n",
    "        if args.rank == 0:\n",
    "            reporter.epoch_start()\n",
    "        for data in data_loader:\n",
    "            img_A = data[\"image_A\"]\n",
    "            img_B = data[\"image_B\"]\n",
    "\n",
    "            res_G = train_step_g(img_A, img_B)\n",
    "            fake_A = res_G[0]\n",
    "            fake_B = res_G[1]\n",
    "            res_D = train_step_d(img_A, img_B, image_pool_A.query(fake_A), image_pool_B.query(fake_B))\n",
    "\n",
    "            if args.rank == 0:\n",
    "                reporter.step_end(res_G, res_D)\n",
    "                reporter.visualizer(img_A, img_B, fake_A, fake_B)\n",
    "        if args.rank == 0:\n",
    "            reporter.epoch_end()\n",
    "        if args.need_profiler:\n",
    "            profiler.analyse()\n",
    "            break\n",
    "    \n",
    "    if args.rank == 0:\n",
    "        reporter.info('==========end training===============')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型推理\n",
    "\n",
    "下面我们通过加载生成器网络模型参数文件来对原图进行风格迁移。\n",
    "\n",
    "推理得到的图片保存在'./outputs/predict'里"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Args:\n",
      "--> platform: Ascend\n",
      "--> device_id: 0\n",
      "--> device_num: 1\n",
      "--> is_save_on_master: 1\n",
      "--> rank: 0\n",
      "--> group_size: 1\n",
      "--> model: ResNet\n",
      "--> init_type: normal\n",
      "--> init_gain: 0.02\n",
      "--> image_size: 256\n",
      "--> batch_size: 1\n",
      "--> pool_size: 50\n",
      "--> beta1: 0.5\n",
      "--> lr: 0.0002\n",
      "--> lr_policy: linear\n",
      "--> max_epoch: 200\n",
      "--> n_epochs: 100\n",
      "--> in_planes: 3\n",
      "--> ngf: 64\n",
      "--> gl_num: 9\n",
      "--> ndf: 64\n",
      "--> dl_num: 3\n",
      "--> slope: 0.2\n",
      "--> norm_mode: instance\n",
      "--> lambda_A: 10.0\n",
      "--> lambda_B: 10.0\n",
      "--> lambda_idt: 0.5\n",
      "--> gan_mode: lsgan\n",
      "--> pad_mode: CONSTANT\n",
      "--> dataroot: ./\n",
      "--> data_dir: trainA\n",
      "--> outputs_dir: ./outputs\n",
      "--> load_ckpt: False\n",
      "--> G_A_ckpt: ./outputs/ckpt/G_A_100.ckpt\n",
      "--> G_B_ckpt: ./outputs/ckpt/G_B_100.ckpt\n",
      "--> D_A_ckpt: ./outputs/ckpt/D_A_100.ckpt\n",
      "--> D_B_ckpt: ./outputs/ckpt/D_B_100.ckpt\n",
      "--> save_checkpoint_epochs: 10\n",
      "--> print_iter: 100\n",
      "--> need_profiler: False\n",
      "--> save_graphs: False\n",
      "--> save_imgs: True\n",
      "--> save_img_nums: 3\n",
      "--> use_random: True\n",
      "--> need_dropout: False\n",
      "--> max_dataset_size: inf\n",
      "--> export_batch_size: 1\n",
      "--> export_file_name: CycleGAN\n",
      "--> export_file_format: MINDIR\n",
      "--> n_epochs_decay: 100\n",
      "--> phase: predict\n",
      "--> dataset_size: 303\n",
      "\n",
      "==========start predict A to B===============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303 303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "save fake_B at ./outputs/predict/fake_B/A (280).png\n",
      "total 303 imgs cost 6437.21 ms, per img cost 21.24\n",
      "==========end predict A to B===============\n",
      "\n",
      "==========start predict B to A===============\n",
      "save fake_A at ./outputs/predict/fake_A/B (291).png\n",
      "total 403 imgs cost 7721.61 ms, per img cost 19.16\n",
      "==========end predict B to A===============\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Cycle GAN test.\"\"\"\n",
    "import os\n",
    "import mindspore as ms\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def predict():\n",
    "    \"\"\"Predict function.\"\"\"\n",
    "    args = get_args(\"predict\")\n",
    "    args.platform = 'Ascend'\n",
    "    args.model = 'ResNet' \n",
    "    \n",
    "    ms.set_context(mode=ms.GRAPH_MODE,\n",
    "                   device_target=args.platform,\n",
    "                   save_graphs=args.save_graphs,\n",
    "                   device_id=args.device_id)\n",
    "    args.rank = 0\n",
    "    args.device_num = 1\n",
    "    if args.platform == \"GPU\":\n",
    "        ms.set_context(enable_graph_kernel=True)\n",
    "    \n",
    "    args.G_A_ckpt = './outputs/ckpt/G_A_100.ckpt'\n",
    "    args.G_B_ckpt = './outputs/ckpt/G_B_100.ckpt'\n",
    "    args.D_A_ckpt = './outputs/ckpt/D_A_100.ckpt'\n",
    "    args.D_B_ckpt = './outputs/ckpt/D_B_100.ckpt'\n",
    "\n",
    "    load_ckpt(args, net_rg_a, net_rg_b)\n",
    "\n",
    "    imgs_out = os.path.join(args.outputs_dir, \"predict\")\n",
    "    if not os.path.exists(imgs_out):\n",
    "        os.makedirs(imgs_out)\n",
    "    if not os.path.exists(os.path.join(imgs_out, \"fake_A\")):\n",
    "        os.makedirs(os.path.join(imgs_out, \"fake_A\"))\n",
    "    if not os.path.exists(os.path.join(imgs_out, \"fake_B\")):\n",
    "        os.makedirs(os.path.join(imgs_out, \"fake_B\"))\n",
    "    \n",
    "    #args.data_dir = 'testA'\n",
    "    args.data_dir = 'trainA'\n",
    "    ds = create_dataset(args)\n",
    "\n",
    "    reporter = Reporter(args)\n",
    "    reporter.start_predict(\"A to B\")\n",
    "\n",
    "    for data in ds.create_dict_iterator(output_numpy=True):\n",
    "        img_A = ms.Tensor(data[\"image\"])\n",
    "        path_A = data[\"image_name\"][0]\n",
    "        if isinstance(path_A, np.bytes_):\n",
    "            path_A = path_A.decode(\"UTF-8\")\n",
    "        path_B = path_A[0:-4] + \"_fake_B.png\"\n",
    "\n",
    "        fake_B = net_rg_a(img_A)\n",
    "        save_image(fake_B, os.path.join(imgs_out, \"fake_B\", path_B))\n",
    "        save_image(img_A, os.path.join(imgs_out, \"fake_B\", path_A))\n",
    "    reporter.info('save fake_B at %s', os.path.join(imgs_out, \"fake_B\",\n",
    "                                                    path_A))\n",
    "    reporter.end_predict()\n",
    "    \n",
    "    #args.data_dir = 'testB'\n",
    "    args.data_dir = 'trainB'\n",
    "    ds = create_dataset(args)\n",
    "\n",
    "    reporter.dataset_size = args.dataset_size\n",
    "    reporter.start_predict(\"B to A\")\n",
    "    \n",
    "    for data in ds.create_dict_iterator(output_numpy=True):\n",
    "        img_B = ms.Tensor(data[\"image\"])\n",
    "        path_B = data[\"image_name\"][0]\n",
    "        if isinstance(path_B, np.bytes_):\n",
    "            path_B = path_B.decode(\"UTF-8\")\n",
    "        path_A = path_B[0:-4] + \"_fake_A.png\"\n",
    "        fake_A = net_rg_b(img_B)\n",
    "        save_image(fake_A, os.path.join(imgs_out, \"fake_A\", path_A))\n",
    "        save_image(img_B, os.path.join(imgs_out, \"fake_A\", path_B))\n",
    "    reporter.info('save fake_A at %s', os.path.join(imgs_out, \"fake_A\",\n",
    "                                                    path_B))\n",
    "    reporter.end_predict()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    predict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型导出\n",
    "\n",
    "下面我们通过`mindspore.export`导出MINDIR文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"export file.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import mindspore as ms\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = get_args(\"export\")\n",
    "    args.G_A_ckpt = './outputs/ckpt/G_A_100.ckpt'\n",
    "    args.G_B_ckpt = './outputs/ckpt/G_B_100.ckpt'\n",
    "    args.D_A_ckpt = './outputs/ckpt/D_A_100.ckpt'\n",
    "    args.D_B_ckpt = './outputs/ckpt/D_B_100.ckpt'\n",
    "    \n",
    "    ms.set_context(mode=ms.GRAPH_MODE, device_target=args.platform)\n",
    "    G_A = get_generator(args)\n",
    "    G_B = get_generator(args)\n",
    "    # Use BatchNorm2d with batchsize=1, affine=False, use_batch_statistics=True instead of InstanceNorm2d\n",
    "    # Use real mean and variance rather than moving_mean and moving_varance in BatchNorm2d\n",
    "    enable_batch_statistics(G_A)\n",
    "    enable_batch_statistics(G_B)\n",
    "    load_ckpt(args, G_A, G_B)\n",
    "\n",
    "    input_shp = [args.export_batch_size, 3, args.image_size, args.image_size]\n",
    "    input_array = ms.Tensor(np.random.uniform(-1.0, 1.0, size=input_shp).astype(np.float32))\n",
    "    G_A_file = f\"{args.export_file_name}_AtoB\"\n",
    "    ms.export(G_A, input_array, file_name=G_A_file, file_format=args.export_file_format)\n",
    "    G_B_file = f\"{args.export_file_name}_BtoA\"\n",
    "    ms.export(G_B, input_array, file_name=G_B_file, file_format=args.export_file_format)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288.875px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
